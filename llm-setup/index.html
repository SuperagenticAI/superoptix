
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="AI Agent Development Framework: Evaluation-First and Optimization-Core.">
      
      
        <meta name="author" content="SuperagenticAI">
      
      
        <link rel="canonical" href="https://docs.super-agentic.ai/llm-setup/">
      
      
        <link rel="prev" href="../guides/troubleshooting-by-symptom/">
      
      
        <link rel="next" href="../environment-setup/">
      
      
        
      
      
      <link rel="icon" href="../favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.1">
    
    
      
        <title>üß† LLM Setup - SUPEROPTIX AI</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.484c7ddc.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Inter:300,300i,400,400i,700,700i%7CFira+Code:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Inter";--md-code-font:"Fira Code"}</style>
      
    
    
      <link rel="stylesheet" href="../stylesheets/extra.css?v=24.0">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="grey" data-md-color-accent="purple">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#llm-setup-guide" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="SUPEROPTIX AI" class="md-header__button md-logo" aria-label="SUPEROPTIX AI" data-md-component="logo">
      
  <img src="../logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            SUPEROPTIX AI
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              üß† LLM Setup
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="grey" data-md-color-accent="purple"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="grey" data-md-color-accent="purple"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="SUPEROPTIX AI" class="md-nav__button md-logo" aria-label="SUPEROPTIX AI" data-md-component="logo">
      
  <img src="../logo.png" alt="logo">

    </a>
    SUPEROPTIX AI
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üè† Home
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    üöÄ Get Started
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    üöÄ Get Started
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../introduction/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üìñ Introduction
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../quick-start/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üöÄ Quick Start
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/golden-workflow/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ‚≠ê Golden Workflow
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/multi-framework-quickstart/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üåê Multi-Framework Quick Start
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../setup/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ‚öôÔ∏è Setup & Installation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/troubleshooting-by-symptom/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üõ†Ô∏è Troubleshooting by Symptom
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    
  
    üß† LLM Setup
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    üß† LLM Setup
  

    
  </span>
  
  

      </a>
      
        

  

<nav class="md-nav md-nav--secondary" aria-label="On this page">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      On this page
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#overview" class="md-nav__link">
    <span class="md-ellipsis">
      
        üéØ Overview
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ollama-recommended" class="md-nav__link">
    <span class="md-ellipsis">
      
        ü¶ô Ollama (Recommended)
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ü¶ô Ollama (Recommended)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#quick-setup" class="md-nav__link">
    <span class="md-ellipsis">
      
        üöÄ Quick Setup
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#install-models-with-superoptix" class="md-nav__link">
    <span class="md-ellipsis">
      
        üì¶ Install Models with SuperOptiX
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#server-management" class="md-nav__link">
    <span class="md-ellipsis">
      
        üñ•Ô∏è Server Management
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#manage-ollama-models" class="md-nav__link">
    <span class="md-ellipsis">
      
        üìã Manage Ollama Models
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gpt-oss-models-openais-open-source" class="md-nav__link">
    <span class="md-ellipsis">
      
        ü§ñ GPT-OSS Models (OpenAI's Open Source)
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ü§ñ GPT-OSS Models (OpenAI&#39;s Open Source)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#apple-silicon-support" class="md-nav__link">
    <span class="md-ellipsis">
      
        üçé Apple Silicon Support
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gpt-oss-model-overview" class="md-nav__link">
    <span class="md-ellipsis">
      
        üéØ GPT-OSS Model Overview
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#key-features" class="md-nav__link">
    <span class="md-ellipsis">
      
        üöÄ Key Features
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#install-gpt-oss-models" class="md-nav__link">
    <span class="md-ellipsis">
      
        üì¶ Install GPT-OSS Models
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="üì¶ Install GPT-OSS Models">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#via-ollama-cross-platform-recommended" class="md-nav__link">
    <span class="md-ellipsis">
      
        Via Ollama (Cross-Platform - RECOMMENDED)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#via-mlx-lm-apple-silicon-native-support" class="md-nav__link">
    <span class="md-ellipsis">
      
        Via MLX-LM (Apple Silicon - Native Support)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#via-huggingface" class="md-nav__link">
    <span class="md-ellipsis">
      
        Via HuggingFace
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#using-gpt-oss-with-superoptix" class="md-nav__link">
    <span class="md-ellipsis">
      
        üéØ Using GPT-OSS with SuperOptiX
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="üéØ Using GPT-OSS with SuperOptiX">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#configure-playbook-for-gpt-oss" class="md-nav__link">
    <span class="md-ellipsis">
      
        Configure Playbook for GPT-OSS
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#starting-mlx-server-for-gpt-oss" class="md-nav__link">
    <span class="md-ellipsis">
      
        üöÄ Starting MLX Server for GPT-OSS
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="üöÄ Starting MLX Server for GPT-OSS">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#basic-usage-examples" class="md-nav__link">
    <span class="md-ellipsis">
      
        Basic Usage Examples
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#manage-gpt-oss-models" class="md-nav__link">
    <span class="md-ellipsis">
      
        üìã Manage GPT-OSS Models
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#performance-recommendations" class="md-nav__link">
    <span class="md-ellipsis">
      
        üéØ Performance Recommendations
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#troubleshooting-gpt-oss" class="md-nav__link">
    <span class="md-ellipsis">
      
        üîß Troubleshooting GPT-OSS
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../environment-setup/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üèóÔ∏è Environment Setup
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../project-structure/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üìÅ Project Structure
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_10" >
        
          
          <label class="md-nav__link" for="__nav_2_10" id="__nav_2_10_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    üéì Tutorials
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_10_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_10">
            <span class="md-nav__icon md-icon"></span>
            
  
    üéì Tutorials
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üìö Tutorials Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/openai-sdk-gepa-optimization/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üîß OpenAI SDK + GEPA Optimization
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    üî¨ Frameworks
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    üî¨ Frameworks
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üìö Frameworks Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/multi-framework/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üåê Comparison
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/framework-feature-matrix/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üìä Feature Matrix
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/openai-sdk-integration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ü§ñ OpenAI SDK
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/claude-sdk-integration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üß† Claude Agent SDK
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/pydantic-ai-integration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üêç Pydantic AI
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/pydantic-ai-mcp-demo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üêç Pydantic AI MCP Demo
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/crewai-integration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üë• CrewAI
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/crewai-task-optimization/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ‚ö° CrewAI Advanced
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/google-adk-integration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üîÆ Google ADK
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/microsoft-framework-integration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üè¢ Microsoft (Legacy)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/deepagents-integration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üåä DeepAgents
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    üìù SuperSpec
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    üìù SuperSpec
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/superspec/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üìù SuperSpec Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/superspec-dsl-reference/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üìó DSL Reference
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/superspec-dsl-examples/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üìô DSL Examples
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/superspec-agent-building/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üèóÔ∏è Agent Building
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/superspec-configuration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ‚öôÔ∏è Configuration
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/superspec-context-engineering/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üß† Context Engineering
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    üõ†Ô∏è Build
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            
  
    üõ†Ô∏è Build
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../agent-patterns/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üé® Agent Patterns
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/agent-discovery/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üîç Agent Discovery
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/agent-development/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ü§ñ Agent Development
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/tool-development/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üîß Tool Development
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/technical-architecture/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üèõÔ∏è Technical Architecture
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Evaluate
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            
  
    Evaluate
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/evaluation-testing/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Evaluation & Testing
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/bdd/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üé≠ RSpec-Style BDD Testing
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" >
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    üéØ Agent Optimization
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            
  
    üéØ Agent Optimization
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/agent-optimization/overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üìñ Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/agent-optimization/prompts/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üí¨ Prompt Optimization
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/agent-optimization/rag/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üîç RAG Optimization
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/agent-optimization/tools/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üõ†Ô∏è Tool Optimization
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/agent-optimization/memory/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üß† Memory Optimization
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/agent-optimization/protocols/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üîå Protocol Optimization (MCP)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/agent-optimization/datasets/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üìä Dataset-Driven Optimization
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/agent-optimization/full-stack-example/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üéØ Full-Stack Example
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8" >
        
          
          <label class="md-nav__link" for="__nav_8" id="__nav_8_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    ‚ö° Optimize
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_8">
            <span class="md-nav__icon md-icon"></span>
            
  
    ‚ö° Optimize
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/gepa-optimization/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üß¨ GEPA Optimizer
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/rlm-experimental/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üß™ RLM (Experimental)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/optimization/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üìà Optimization Guide
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/dspy-optimizers/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üî¨ DSPy Optimizers
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/openai-sdk-gepa-optimization/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üîß OpenAI SDK + GEPA Optimization
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/rag-optimization/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üîç RAG Optimization
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/mcp-optimization/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üîå MCP Optimization
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/memory-optimization/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üí° Memory Optimization
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_9" >
        
          
          <label class="md-nav__link" for="__nav_9" id="__nav_9_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    üéº Orchestrate
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_9">
            <span class="md-nav__icon md-icon"></span>
            
  
    üéº Orchestrate
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/orchestra-development/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üéº Orchestra Development
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/first-orchestra/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üéº Multi-Agent Orchestra
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_10" >
        
          
          <label class="md-nav__link" for="__nav_10" id="__nav_10_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    üìä Monitor
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_10_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_10">
            <span class="md-nav__icon md-icon"></span>
            
  
    üìä Monitor
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/observability/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üìä Observability Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/mlflow-guide/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üßø MLFlow
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/langfuse-integration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üß¨ LangFuse
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/logfire-integration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üî• LogFire
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/weights-biases-integration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üìà Weights & Biases
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/observability-comparison/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ‚öñÔ∏è Comparison
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/enhanced-observability/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üöÄ Enhanced
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_11" >
        
          
          <label class="md-nav__link" for="__nav_11" id="__nav_11_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    üóÑÔ∏è Context
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_11_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_11">
            <span class="md-nav__icon md-icon"></span>
            
  
    üóÑÔ∏è Context
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/mcp-rag-complete-guide/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üîç RAG & MCP Guide
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/rag/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üìö RAG Configuration
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/protocol-first-agents/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üîå MCP Protocol
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/dataset-import/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üìä Dataset Import
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/memory/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üß† Memory Systems
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_12" >
        
          
          <label class="md-nav__link" for="__nav_12" id="__nav_12_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    üîå Integrations
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_12_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_12">
            <span class="md-nav__icon md-icon"></span>
            
  
    üîå Integrations
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/agents/optimas-examples/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ‚ö° Optimas
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/optimas-integration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ‚ö° Optimas Guide
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/stackone-integration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üóÇÔ∏è StackOne Integration
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/stackone-claude-sdk/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üóÇÔ∏è StackOne + Claude SDK
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/agents/rag-chroma-demo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üö• ChromaDB
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/agents/rag-lancedb-demo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üçÄ LanceDB
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/agents/weaviate-demo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üî∞ Weaviate
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/agents/qdrant-demo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üî∏ Qdrant
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/agents/milvus-demo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üëÅÔ∏è Milvus
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/agents/tools-demo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üõ†Ô∏è Tools
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/agents/memory-demo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üß† Memory
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/agents/observability-demo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üìä Observability
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/agents/mlflow-integration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üßø MLFlow
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/agents/langfuse-integration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üß¨ LangFuse
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/agents/gepa-integration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üöÄ GEPA
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_13" >
        
          
          <label class="md-nav__link" for="__nav_13" id="__nav_13_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    üíª CLI
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_13_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_13">
            <span class="md-nav__icon md-icon"></span>
            
  
    üíª CLI
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/cli-complete-guide/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üìò CLI Complete Guide
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/cli.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üìñ CLI Reference
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_14" >
        
          
          <label class="md-nav__link" for="__nav_14" id="__nav_14_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    ‚ú® Super CLI (Beta)
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_14_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_14">
            <span class="md-nav__icon md-icon"></span>
            
  
    ‚ú® Super CLI (Beta)
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/super-cli/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üí¨ Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/conversational-interface/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üîß Technical Details
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_15" >
        
          
          <label class="md-nav__link" for="__nav_15" id="__nav_15_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    ü§ñ Models
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_15_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_15">
            <span class="md-nav__icon md-icon"></span>
            
  
    ü§ñ Models
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/model-management/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üß† Model Management
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/model-intelligence/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üí° Model Intelligence
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_15_3" >
        
          
          <label class="md-nav__link" for="__nav_15_3" id="__nav_15_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    üíª Local Inference
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_15_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_15_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    üíª Local Inference
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/agents/mlx-demo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üíª MLX (Apple Silicon)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/agents/ollama-demo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üêº Ollama
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/agents/huggingface-demo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ü§ó HuggingFace
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/agents/lmstudio-demo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üéõÔ∏è LM Studio
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_15_4" >
        
          
          <label class="md-nav__link" for="__nav_15_4" id="__nav_15_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    ‚òÅÔ∏è Cloud
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_15_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_15_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    ‚òÅÔ∏è Cloud
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/cloud-inference/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ‚òÅÔ∏è Cloud Inference (OpenAI, Anthropic, Google)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/vllm-inference/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üöÄ vLLM (High-Performance Serving)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/sglang-inference/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ‚ö° SGLang (Structured Generation)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_16" >
        
          
          <label class="md-nav__link" for="__nav_16" id="__nav_16_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    üìö Examples
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_16_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_16">
            <span class="md-nav__icon md-icon"></span>
            
  
    üìö Examples
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üìö Examples Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/agents/optimas-examples/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ‚ö° Optimas
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/agents/rag-chroma-demo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üö• ChromaDB
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/agents/rag-lancedb-demo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üçÄ LanceDB
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/agents/weaviate-demo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üî∞ Weaviate
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/agents/qdrant-demo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üî∏ Qdrant
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/agents/milvus-demo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üëÅÔ∏è Milvus
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/agents/tools-demo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üõ†Ô∏è Tools
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/agents/memory-demo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üß† Memory
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/agents/observability-demo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üìä Observability
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/agents/mlflow-integration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üßø MLFlow
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/agents/langfuse-integration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üß¨ LangFuse
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/agents/weights-biases-demo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üìà Weights & Biases
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/agents/gepa-integration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üöÄ GEPA
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_17" >
        
          
          <label class="md-nav__link" for="__nav_17" id="__nav_17_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    üéØ Techniques
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_17_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_17">
            <span class="md-nav__icon md-icon"></span>
            
  
    üéØ Techniques
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üéØ Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/memory/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üß† Memory Systems
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/memory-optimization/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üí° Memory Optimization
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/rag/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üìö RAG Configuration
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/optimization/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üìà Optimization Guide
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/evaluation-testing/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Evaluation & Testing
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/observability/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üìä Observability Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/bdd/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üé≠ RSpec-Style BDD Testing
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/cicd-integration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üîÑ CI/CD Integration
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/rails-analogy/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üöÇ Rails Analogy (For Rails Devs)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_18" >
        
          
          <label class="md-nav__link" for="__nav_18" id="__nav_18_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    üõçÔ∏è Marketplace
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_18_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_18">
            <span class="md-nav__icon md-icon"></span>
            
  
    üõçÔ∏è Marketplace
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/marketplace/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üõçÔ∏è Marketplace Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_19" >
        
          
          <label class="md-nav__link" for="__nav_19" id="__nav_19_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Responsible AI
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_19_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_19">
            <span class="md-nav__icon md-icon"></span>
            
  
    Responsible AI
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/responsible-ai/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Responsible AI Guide
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_20" >
        
          
          <label class="md-nav__link" for="__nav_20" id="__nav_20_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    üè¢ Company
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_20_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_20">
            <span class="md-nav__icon md-icon"></span>
            
  
    üè¢ Company
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../superagentic-ai/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üåü Superagentic AI
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_21" >
        
          
          <label class="md-nav__link" for="__nav_21" id="__nav_21_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    üìñ Reference
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_21_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_21">
            <span class="md-nav__icon md-icon"></span>
            
  
    üìñ Reference
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/index.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üìö Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_21_2" >
        
          
          <label class="md-nav__link" for="__nav_21_2" id="__nav_21_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    üîß API Reference
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_21_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_21_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    üîß API Reference
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/api/index.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    API Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/api/superspec.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üìù SuperSpec API
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/api/gepa.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üß¨ GEPA API
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/api/dspy-optimizers.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üî¨ DSPy Optimizers API
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/api/runners.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üèÉ Runners API
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/api/memory.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üß† Memory API
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/api/models.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ü§ñ Models API
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/api/tools.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üîß Tools API
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/api/observability.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üìä Observability API
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/api/cli.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üíª CLI API
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/api/core.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üîß Core API
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../faq/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ‚ùì FAQ
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../debugging-guide/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üêõ Debugging
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

  

<nav class="md-nav md-nav--secondary" aria-label="On this page">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      On this page
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#overview" class="md-nav__link">
    <span class="md-ellipsis">
      
        üéØ Overview
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ollama-recommended" class="md-nav__link">
    <span class="md-ellipsis">
      
        ü¶ô Ollama (Recommended)
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ü¶ô Ollama (Recommended)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#quick-setup" class="md-nav__link">
    <span class="md-ellipsis">
      
        üöÄ Quick Setup
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#install-models-with-superoptix" class="md-nav__link">
    <span class="md-ellipsis">
      
        üì¶ Install Models with SuperOptiX
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#server-management" class="md-nav__link">
    <span class="md-ellipsis">
      
        üñ•Ô∏è Server Management
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#manage-ollama-models" class="md-nav__link">
    <span class="md-ellipsis">
      
        üìã Manage Ollama Models
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gpt-oss-models-openais-open-source" class="md-nav__link">
    <span class="md-ellipsis">
      
        ü§ñ GPT-OSS Models (OpenAI's Open Source)
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ü§ñ GPT-OSS Models (OpenAI&#39;s Open Source)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#apple-silicon-support" class="md-nav__link">
    <span class="md-ellipsis">
      
        üçé Apple Silicon Support
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gpt-oss-model-overview" class="md-nav__link">
    <span class="md-ellipsis">
      
        üéØ GPT-OSS Model Overview
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#key-features" class="md-nav__link">
    <span class="md-ellipsis">
      
        üöÄ Key Features
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#install-gpt-oss-models" class="md-nav__link">
    <span class="md-ellipsis">
      
        üì¶ Install GPT-OSS Models
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="üì¶ Install GPT-OSS Models">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#via-ollama-cross-platform-recommended" class="md-nav__link">
    <span class="md-ellipsis">
      
        Via Ollama (Cross-Platform - RECOMMENDED)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#via-mlx-lm-apple-silicon-native-support" class="md-nav__link">
    <span class="md-ellipsis">
      
        Via MLX-LM (Apple Silicon - Native Support)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#via-huggingface" class="md-nav__link">
    <span class="md-ellipsis">
      
        Via HuggingFace
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#using-gpt-oss-with-superoptix" class="md-nav__link">
    <span class="md-ellipsis">
      
        üéØ Using GPT-OSS with SuperOptiX
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="üéØ Using GPT-OSS with SuperOptiX">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#configure-playbook-for-gpt-oss" class="md-nav__link">
    <span class="md-ellipsis">
      
        Configure Playbook for GPT-OSS
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#starting-mlx-server-for-gpt-oss" class="md-nav__link">
    <span class="md-ellipsis">
      
        üöÄ Starting MLX Server for GPT-OSS
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="üöÄ Starting MLX Server for GPT-OSS">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#basic-usage-examples" class="md-nav__link">
    <span class="md-ellipsis">
      
        Basic Usage Examples
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#manage-gpt-oss-models" class="md-nav__link">
    <span class="md-ellipsis">
      
        üìã Manage GPT-OSS Models
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#performance-recommendations" class="md-nav__link">
    <span class="md-ellipsis">
      
        üéØ Performance Recommendations
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#troubleshooting-gpt-oss" class="md-nav__link">
    <span class="md-ellipsis">
      
        üîß Troubleshooting GPT-OSS
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
                



  


  <nav class="md-path" aria-label="Navigation" >
    <ol class="md-path__list">
      
        
  
  
    <li class="md-path__item">
      <a href=".." class="md-path__link">
        
  <span class="md-ellipsis">
    üè† Home
  </span>

      </a>
    </li>
  

      
      
        
  
  
    
    
      <li class="md-path__item">
        <a href="../introduction/" class="md-path__link">
          
  <span class="md-ellipsis">
    üöÄ Get Started
  </span>

        </a>
      </li>
    
  

      
    </ol>
  </nav>

              
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="llm-setup-guide">ü§ñ LLM Setup Guide</h1>
<p>Welcome to SuperOptiX's LLM Setup Guide! This guide will help you configure and use local language models for your AI agents. We focus on local models for privacy, speed, and cost-effectiveness.</p>
<div class="admonition tip">
<p class="admonition-title">üöÄ Quick Start</p>
<p><strong>New to local models?</strong> Start with <a href="#ollama-recommended">Ollama</a> - it's the easiest option for beginners!</p>
</div>
<h2 id="overview">üéØ Overview</h2>
<p>SuperOptiX supports multiple local model backends, each optimized for different use cases:</p>
<table>
<thead>
<tr>
<th>Backend</th>
<th>Best For</th>
<th>Platform</th>
<th>Ease of Use</th>
<th>Performance</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ü¶ô Ollama</strong></td>
<td>Beginners, All platforms</td>
<td>Cross-platform</td>
<td>‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê</td>
<td>‚≠ê‚≠ê‚≠ê‚≠ê</td>
</tr>
<tr>
<td><strong>ü§ñ GPT-OSS</strong></td>
<td>Advanced reasoning, Agentic tasks</td>
<td>Cross-platform</td>
<td>‚≠ê‚≠ê‚≠ê‚≠ê</td>
<td>‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê</td>
</tr>
<tr>
<td><strong>üçé MLX</strong></td>
<td>Apple Silicon users</td>
<td>macOS only</td>
<td>‚≠ê‚≠ê‚≠ê‚≠ê</td>
<td>‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê</td>
</tr>
<tr>
<td><strong>üéÆ LM Studio</strong></td>
<td>Windows users</td>
<td>Windows/macOS</td>
<td>‚≠ê‚≠ê‚≠ê</td>
<td>‚≠ê‚≠ê‚≠ê‚≠ê</td>
</tr>
<tr>
<td><strong>ü§ó HuggingFace</strong></td>
<td>Advanced users</td>
<td>All platforms</td>
<td>‚≠ê‚≠ê</td>
<td>‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê</td>
</tr>
</tbody>
</table>
<div class="admonition warning">
<p class="admonition-title">Production Inference Engines</p>
<p><strong>vLLM, SGLang, and TGI</strong> are not included in the current version of SuperOptiX. These production-worthy inference engines are part of our enterprise offering.</p>
</div>
<h2 id="ollama-recommended">ü¶ô Ollama (Recommended)</h2>
<p><strong>Ollama</strong> is the easiest way to run local models on any platform. Perfect for beginners!</p>
<h3 id="quick-setup">üöÄ Quick Setup</h3>
<div class="tabbed-set tabbed-alternate" data-tabs="1:3"><input checked="checked" id="__tabbed_1_1" name="__tabbed_1" type="radio" /><input id="__tabbed_1_2" name="__tabbed_1" type="radio" /><input id="__tabbed_1_3" name="__tabbed_1" type="radio" /><div class="tabbed-labels"><label for="__tabbed_1_1">üçé macOS</label><label for="__tabbed_1_2">üêß Linux</label><label for="__tabbed_1_3">ü™ü Windows</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Install Ollama</span>
curl<span class="w"> </span>-fsSL<span class="w"> </span>https://ollama.ai/install.sh<span class="w"> </span><span class="p">|</span><span class="w"> </span>sh

<span class="c1"># Start Ollama (runs in background)</span>
ollama<span class="w"> </span>serve
</code></pre></div>
</div>
<div class="tabbed-block">
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Install Ollama</span>
curl<span class="w"> </span>-fsSL<span class="w"> </span>https://ollama.ai/install.sh<span class="w"> </span><span class="p">|</span><span class="w"> </span>sh

<span class="c1"># Start Ollama</span>
ollama<span class="w"> </span>serve
</code></pre></div>
</div>
<div class="tabbed-block">
<div class="language-powershell highlight"><pre><span></span><code><span class="c"># Download from https://ollama.ai/download</span>
<span class="c"># Or use winget</span>
<span class="n">winget</span> <span class="n">install</span> <span class="n">Ollama</span><span class="p">.</span><span class="n">Ollama</span>

<span class="c"># Start Ollama</span>
<span class="n">ollama</span> <span class="n">serve</span>
</code></pre></div>
</div>
</div>
</div>
<h3 id="install-models-with-superoptix">üì¶ Install Models with SuperOptiX</h3>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Install recommended models by tier</span>
super<span class="w"> </span>model<span class="w"> </span>install<span class="w"> </span>llama3.2:1b<span class="w">      </span><span class="c1"># Oracles tier - Small tasks, fast responses</span>
super<span class="w"> </span>model<span class="w"> </span>install<span class="w"> </span>llama3.2:8b<span class="w">      </span><span class="c1"># Genies tier - Complex reasoning, tools, memory</span>
super<span class="w"> </span>model<span class="w"> </span>install<span class="w"> </span>llama3.2:3b<span class="w">      </span><span class="c1"># Alternative small model</span>
super<span class="w"> </span>model<span class="w"> </span>install<span class="w"> </span>qwen2.5:7b<span class="w">       </span><span class="c1"># Great all-rounder</span>
</code></pre></div>
<details><summary><strong>Show Output</strong></summary>

<div class="language-text highlight"><pre><span></span><code>üöÄ SuperOptiX Model Intelligence - Installing llama3.2:3b
ü¶ô Pulling model llama3.2:3b from Ollama...
‚è≥ This may take a few minutes depending on your internet connection and model size.

pulling manifest 
pulling dde5aa3fc5ff: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè 2.0 GB                         
pulling 966de95ca8a6: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè 1.4 KB                         
pulling fcc5a6bec9da: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè 7.7 KB                         
pulling a70ff7e570d9: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè 6.0 KB                         
pulling 56bb8bd477a5: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   96 B                         
pulling 34bb5ab01051: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  561 B                         
verifying sha256 digest 
writing manifest 
success 
Model pulled successfully!

üí° You can now use it with SuperOptiX:
  super model dspy ollama/llama3.2:3b

üìä Model details:
  ‚Ä¢ Size: small
  ‚Ä¢ Task: chat
  ‚Ä¢ Parameters: 3B

üéâ Installation completed successfully!
ü¶ô Ollama running on http://localhost:11434 ready to use with SuperOptiX!
</code></pre></div>

</details>

<h3 id="server-management">üñ•Ô∏è Server Management</h3>
<p><strong>üí° Important</strong>: Ollama automatically starts its server when you run <code>ollama serve</code> or when you first use a model. You don't need to manually start the server unless you want custom configuration.</p>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Start Ollama server (runs on port 11434 by default)</span>
ollama<span class="w"> </span>serve

<span class="c1"># Or simply use a model - server starts automatically</span>
ollama<span class="w"> </span>run<span class="w"> </span>llama3.2:1b
</code></pre></div>
<p><strong>üîß Custom Configuration</strong>: Only start the server manually if you need:
- Different port: <code>OLLAMA_HOST=0.0.0.0:8080 ollama serve</code>
- Custom model path: <code>OLLAMA_MODELS=/custom/path ollama serve</code>
- GPU configuration: <code>OLLAMA_GPU_LAYERS=35 ollama serve</code></p>
<p><strong>Automatic Detection</strong>: SuperOptiX automatically detects and connects to Ollama running on the default port (11434). No additional configuration needed!</p>
<h3 id="manage-ollama-models">üìã Manage Ollama Models</h3>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># List installed models</span>
super<span class="w"> </span>model<span class="w"> </span>list<span class="w"> </span>--backend<span class="w"> </span>ollama
</code></pre></div>
<p><strong>Example Output:</strong>
<div class="language-text highlight"><pre><span></span><code>                üöÄ SuperOptiX Model Intelligence - 3 models                 
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ Model                   ‚îÉ  Backend  ‚îÉ    Status    ‚îÉ  Size   ‚îÉ   Task    ‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ llama3.1:8b             ‚îÇ ü¶ô ollama ‚îÇ installed ‚îÇ medium  ‚îÇ   chat    ‚îÇ
‚îÇ llama3.2:1b             ‚îÇ ü¶ô ollama ‚îÇ installed ‚îÇ  tiny   ‚îÇ   chat    ‚îÇ
‚îÇ nomic-embed-text:latest ‚îÇ ü¶ô ollama ‚îÇ installed ‚îÇ Unknown ‚îÇ embedding ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre></div></p>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Get model information</span>
super<span class="w"> </span>model<span class="w"> </span>info<span class="w"> </span>llama3.2:3b

<span class="c1"># List all available models</span>
super<span class="w"> </span>model<span class="w"> </span>list<span class="w"> </span>--all
</code></pre></div>
<h2 id="gpt-oss-models-openais-open-source">ü§ñ GPT-OSS Models (OpenAI's Open Source)</h2>
<p><strong>GPT-OSS</strong> models are OpenAI's latest open-weight language models designed for powerful reasoning, agentic tasks, and versatile developer use cases. SuperOptiX now supports both GPT-OSS-20B and GPT-OSS-120B models with <strong>native Apple Silicon support</strong>!</p>
<h3 id="apple-silicon-support">üçé Apple Silicon Support</h3>
<p><strong>MLX-LM v0.26.3</strong> now provides native Apple Silicon support for GPT-OSS models, resolving the mixed precision issues that previously prevented these models from running on Apple Silicon.</p>
<table>
<thead>
<tr>
<th>Backend</th>
<th>Model</th>
<th>Status</th>
<th>Performance</th>
<th>Apple Silicon</th>
<th><strong>Recommendation</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ü¶ô Ollama</strong></td>
<td>gpt-oss:20b</td>
<td><strong>Works</strong></td>
<td><strong>19.7 t/s</strong></td>
<td><strong>Optimized format</strong></td>
<td><strong>‚≠ê RECOMMENDED</strong></td>
</tr>
<tr>
<td><strong>üçé MLX-LM</strong></td>
<td>openai_gpt-oss-20b</td>
<td><strong>Works</strong></td>
<td>5.2 t/s</td>
<td><strong>Native support</strong></td>
<td><strong>Apple Silicon only</strong></td>
</tr>
<tr>
<td><strong>ü§ó HuggingFace</strong></td>
<td>openai/gpt-oss-20b</td>
<td><strong>Broken</strong></td>
<td>N/A</td>
<td><strong>Mixed precision errors</strong></td>
<td><strong>Avoid on Apple Silicon</strong></td>
</tr>
</tbody>
</table>
<h3 id="gpt-oss-model-overview">üéØ GPT-OSS Model Overview</h3>
<table>
<thead>
<tr>
<th>Model</th>
<th>Parameters</th>
<th>Active Parameters</th>
<th>Best For</th>
<th>Hardware Requirements</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>GPT-OSS-20B</strong></td>
<td>21B</td>
<td>3.6B</td>
<td>Lower latency, local/specialized use cases</td>
<td>16GB+ RAM</td>
</tr>
<tr>
<td><strong>GPT-OSS-120B</strong></td>
<td>117B</td>
<td>5.1B</td>
<td>Production, general purpose, high reasoning</td>
<td>Single H100 GPU</td>
</tr>
</tbody>
</table>
<div class="admonition tip">
<p class="admonition-title">üöÄ <strong>Recommended: Use Ollama for GPT-OSS Models</strong></p>
<p><strong>For the best performance and reliability with GPT-OSS models, we recommend using Ollama:</strong></p>
<ul>
<li><strong>Best Performance</strong>: 19.7 t/s vs 5.2 t/s (MLX) vs N/A (HuggingFace)</li>
<li><strong>Cross-Platform</strong>: Works on all platforms (Windows, macOS, Linux)</li>
<li><strong>Easy Setup</strong>: Simple installation and model management</li>
<li><strong>Optimized Format</strong>: GGUF format optimized for local inference</li>
<li><strong>No Server Required</strong>: Direct model execution</li>
</ul>
<p><strong>Install and use GPT-OSS with Ollama:</strong>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Install GPT-OSS models</span>
super<span class="w"> </span>model<span class="w"> </span>install<span class="w"> </span>gpt-oss:20b
super<span class="w"> </span>model<span class="w"> </span>install<span class="w"> </span>gpt-oss:120b

<span class="c1"># Use in playbooks</span>
language_model:
<span class="w">  </span>provider:<span class="w"> </span>ollama
<span class="w">  </span>model:<span class="w"> </span>gpt-oss:20b
<span class="w">  </span>api_base:<span class="w"> </span>http://localhost:11434
</code></pre></div></p>
</div>
<h3 id="key-features">üöÄ Key Features</h3>
<ul>
<li><strong>üîì Apache 2.0 License:</strong> Build freely without copyleft restrictions</li>
<li><strong>‚ö° Native MXFP4 Quantization:</strong> Optimized for efficient inference</li>
<li><strong>üçé Apple Silicon Native:</strong> No more mixed precision issues</li>
</ul>
<h3 id="install-gpt-oss-models">üì¶ Install GPT-OSS Models</h3>
<h4 id="via-ollama-cross-platform-recommended">Via Ollama (Cross-Platform - <strong>RECOMMENDED</strong>)</h4>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Install GPT-OSS models via Ollama (Best Performance)</span>
super<span class="w"> </span>model<span class="w"> </span>install<span class="w"> </span>gpt-oss:20b
super<span class="w"> </span>model<span class="w"> </span>install<span class="w"> </span>gpt-oss:120b

<span class="c1"># Or use direct Ollama commands</span>
ollama<span class="w"> </span>pull<span class="w"> </span>gpt-oss:20b
ollama<span class="w"> </span>pull<span class="w"> </span>gpt-oss:120b

<span class="c1"># Run with Ollama backend</span>
super<span class="w"> </span>model<span class="w"> </span>run<span class="w"> </span>gpt-oss:20b<span class="w"> </span><span class="s2">&quot;Your prompt&quot;</span><span class="w"> </span>--backend<span class="w"> </span>ollama
</code></pre></div>
<h4 id="via-mlx-lm-apple-silicon-native-support">Via MLX-LM (Apple Silicon - Native Support)</h4>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Install GPT-OSS models via Ollama</span>
super<span class="w"> </span>model<span class="w"> </span>install<span class="w"> </span>gpt-oss:20b
super<span class="w"> </span>model<span class="w"> </span>install<span class="w"> </span>gpt-oss:120b

<span class="c1"># Or use direct Ollama commands</span>
ollama<span class="w"> </span>pull<span class="w"> </span>gpt-oss:20b
ollama<span class="w"> </span>pull<span class="w"> </span>gpt-oss:120b

<span class="c1"># Run with Ollama backend</span>
super<span class="w"> </span>model<span class="w"> </span>run<span class="w"> </span>gpt-oss:20b<span class="w"> </span><span class="s2">&quot;Your prompt&quot;</span><span class="w"> </span>--backend<span class="w"> </span>ollama
</code></pre></div>
<details><summary><strong>Show Ollama Installation Output</strong></summary>

<div class="language-text highlight"><pre><span></span><code>üöÄ SuperOptiX Model Intelligence - Installing gpt-oss:20b
ü¶ô Pulling model gpt-oss:20b from Ollama...
‚è≥ This may take a few minutes depending on your internet connection and model size.

pulling manifest 
pulling 8f7b3c2a1d4e: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè 12.5 GB                         
pulling 9a2b4c6d8e0f: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè 1.2 KB                         
verifying sha256 digest 
writing manifest 
success 
Model pulled successfully!

üí° You can now use it with SuperOptiX:
  super model dspy ollama/gpt-oss:20b

üìä Model details:
  ‚Ä¢ Size: large
  ‚Ä¢ Task: chat
  ‚Ä¢ Parameters: 21B (3.6B active)

üéâ Installation completed successfully!
ü¶ô Ollama running on http://localhost:11434 ready to use with SuperOptiX!
</code></pre></div>

</details>

<h4 id="via-huggingface">Via HuggingFace</h4>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Install GPT-OSS models via HuggingFace</span>
super<span class="w"> </span>model<span class="w"> </span>install<span class="w"> </span>openai/gpt-oss-20b<span class="w"> </span>--backend<span class="w"> </span>huggingface
super<span class="w"> </span>model<span class="w"> </span>install<span class="w"> </span>openai/gpt-oss-120b<span class="w"> </span>--backend<span class="w"> </span>huggingface

<span class="c1"># Start HuggingFace server</span>
super<span class="w"> </span>model<span class="w"> </span>server<span class="w"> </span>huggingface<span class="w"> </span>openai/gpt-oss-20b<span class="w"> </span>--port<span class="w"> </span><span class="m">8001</span>
super<span class="w"> </span>model<span class="w"> </span>server<span class="w"> </span>huggingface<span class="w"> </span>openai/gpt-oss-120b<span class="w"> </span>--port<span class="w"> </span><span class="m">8002</span>
</code></pre></div>
<details><summary><strong>Show HuggingFace Installation Output</strong></summary>

<div class="language-text highlight"><pre><span></span><code>üöÄ SuperOptiX Model Intelligence - Installing openai/gpt-oss-20b
ü§ó Downloading model from HuggingFace...
‚è≥ This may take several minutes depending on your internet connection and model size.

Downloading model files...
  ‚Ä¢ config.json: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè 2.1 KB
  ‚Ä¢ model.safetensors: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè 12.5 GB
  ‚Ä¢ tokenizer.json: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè 1.8 MB
  ‚Ä¢ tokenizer_config.json: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè 1.2 KB

Model downloaded successfully!

üí° You can now use it with SuperOptiX:
  super model server huggingface openai/gpt-oss-20b --port 8001

üìä Model details:
  ‚Ä¢ Size: large
  ‚Ä¢ Task: chat
  ‚Ä¢ Parameters: 21B (3.6B active)
  ‚Ä¢ License: Apache 2.0

üéâ Installation completed successfully!
</code></pre></div>

</details>

<h3 id="using-gpt-oss-with-superoptix">üéØ Using GPT-OSS with SuperOptiX</h3>
<h4 id="configure-playbook-for-gpt-oss"><strong>Configure Playbook for GPT-OSS</strong></h4>
<div class="language-yaml highlight"><pre><span></span><code><span class="c1"># Example playbook configuration for GPT-OSS</span>
<span class="nt">language_model</span><span class="p">:</span>
<span class="w">  </span><span class="nt">provider</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">mlx</span><span class="w">  </span><span class="c1"># or ollama or huggingface</span>
<span class="w">  </span><span class="nt">model</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">lmstudio-community/gpt-oss-20b-MLX-8bit</span><span class="w">  </span><span class="c1"># for MLX-LM</span>
<span class="w">  </span><span class="c1"># model: gpt-oss:20b  # for Ollama</span>
<span class="w">  </span><span class="c1"># model: openai/gpt-oss-20b  # for HuggingFace</span>
<span class="w">  </span><span class="nt">api_base</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">http://localhost:11434</span><span class="w">  </span><span class="c1"># for Ollama</span>
<span class="w">  </span><span class="c1"># api_base: http://localhost:8001  # for HuggingFace</span>
<span class="w">  </span><span class="nt">temperature</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.7</span>
<span class="w">  </span><span class="nt">max_tokens</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2048</span>

<span class="c1"># GPT-OSS Language Model Configuration Examples</span>

<span class="err">**</span><span class="l l-Scalar l-Scalar-Plain">ü¶ô Ollama Backend (Cross-platform - RECOMMENDED):**</span>
<span class="err">```</span><span class="l l-Scalar l-Scalar-Plain">yaml</span>
<span class="nt">language_model</span><span class="p">:</span>
<span class="w">  </span><span class="nt">provider</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ollama</span>
<span class="w">  </span><span class="nt">model</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">gpt-oss:20b</span>
<span class="w">  </span><span class="nt">api_base</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">http://localhost:11434</span>
<span class="w">  </span><span class="nt">temperature</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.7</span>
<span class="w">  </span><span class="nt">max_tokens</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">4096</span>
</code></pre></div>
<p><strong>üçé MLX Backend (Apple Silicon - Native Support):</strong>
<div class="language-yaml highlight"><pre><span></span><code><span class="nt">language_model</span><span class="p">:</span>
<span class="w">  </span><span class="nt">provider</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">mlx</span>
<span class="w">  </span><span class="nt">model</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">lmstudio-community/gpt-oss-20b-MLX-8bit</span>
<span class="w">  </span><span class="nt">api_base</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">http://localhost:8000</span>
<span class="w">  </span><span class="nt">temperature</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.7</span>
<span class="w">  </span><span class="nt">max_tokens</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">4096</span>
</code></pre></div></p>
<p><strong>ü§ó HuggingFace Backend (Limited on Apple Silicon):</strong>
<div class="language-yaml highlight"><pre><span></span><code><span class="nt">language_model</span><span class="p">:</span>
<span class="w">  </span><span class="nt">provider</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">huggingface</span>
<span class="w">  </span><span class="nt">model</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">openai/gpt-oss-20b</span>
<span class="w">  </span><span class="nt">api_base</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">http://localhost:8001</span>
<span class="w">  </span><span class="nt">temperature</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.7</span>
<span class="w">  </span><span class="nt">max_tokens</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">4096</span>
</code></pre></div></p>
<h3 id="starting-mlx-server-for-gpt-oss">üöÄ <strong>Starting MLX Server for GPT-OSS</strong></h3>
<p>Before using GPT-OSS with MLX in your playbook, start the MLX server:</p>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Start MLX server for GPT-OSS model</span>
super<span class="w"> </span>model<span class="w"> </span>server<span class="w"> </span>mlx<span class="w"> </span>lmstudio-community/gpt-oss-20b-MLX-8bit<span class="w"> </span>--port<span class="w"> </span><span class="m">8000</span>

<span class="c1"># Or start on a different port</span>
super<span class="w"> </span>model<span class="w"> </span>server<span class="w"> </span>mlx<span class="w"> </span>lmstudio-community/gpt-oss-20b-MLX-8bit<span class="w"> </span>--port<span class="w"> </span><span class="m">9000</span>
</code></pre></div>
<p><strong>Server Output:</strong>
<div class="language-text highlight"><pre><span></span><code>üçé MLX Local Server
Starting MLX server for lmstudio-community/gpt-oss-20b-MLX-8bit on port 8000...
üöÄ Starting MLX server...
python -m mlx_lm.server --model lmstudio-community/gpt-oss-20b-MLX-8bit --port 8000
MLX server is running on http://localhost:8000
</code></pre></div></p>
<p><strong>Note:</strong> Keep the server running while using GPT-OSS models in your playbooks.</p>
<div class="language-text highlight"><pre><span></span><code>#### **Test GPT-OSS Models**

```bash
# Test with MLX-LM backend (Apple Silicon - Native)
super model run lmstudio-community/gpt-oss-20b-MLX-8bit &quot;Explain quantum computing with detailed reasoning&quot; --backend mlx

# Test with Ollama backend (Cross-platform - Best Performance)
super model run gpt-oss:20b &quot;Explain quantum computing with detailed reasoning&quot; --backend ollama

# Test with HuggingFace backend (Limited on Apple Silicon)
super model run openai/gpt-oss-20b &quot;Write a Python function to solve the traveling salesman problem&quot; --backend huggingface
</code></pre></div>
<h4 id="basic-usage-examples"><strong>Basic Usage Examples</strong></h4>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># MLX-LM (Apple Silicon - Native support)</span>
super<span class="w"> </span>model<span class="w"> </span>run<span class="w"> </span>lmstudio-community/gpt-oss-20b-MLX-8bit<span class="w"> </span><span class="s2">&quot;What is 2+2?&quot;</span><span class="w"> </span>--backend<span class="w"> </span>mlx
super<span class="w"> </span>model<span class="w"> </span>run<span class="w"> </span>lmstudio-community/gpt-oss-20b-MLX-8bit<span class="w"> </span><span class="s2">&quot;Explain machine learning&quot;</span><span class="w"> </span>--backend<span class="w"> </span>mlx
super<span class="w"> </span>model<span class="w"> </span>run<span class="w"> </span>lmstudio-community/gpt-oss-20b-MLX-8bit<span class="w"> </span><span class="s2">&quot;Design a distributed system architecture&quot;</span><span class="w"> </span>--backend<span class="w"> </span>mlx

<span class="c1"># Ollama (Cross-platform - Best performance)</span>
super<span class="w"> </span>model<span class="w"> </span>run<span class="w"> </span>gpt-oss:20b<span class="w"> </span><span class="s2">&quot;What is 2+2?&quot;</span><span class="w"> </span>--backend<span class="w"> </span>ollama
super<span class="w"> </span>model<span class="w"> </span>run<span class="w"> </span>gpt-oss:20b<span class="w"> </span><span class="s2">&quot;Explain machine learning&quot;</span><span class="w"> </span>--backend<span class="w"> </span>ollama
super<span class="w"> </span>model<span class="w"> </span>run<span class="w"> </span>gpt-oss:20b<span class="w"> </span><span class="s2">&quot;Design a distributed system architecture&quot;</span><span class="w"> </span>--backend<span class="w"> </span>ollama
</code></pre></div>
<h3 id="manage-gpt-oss-models">üìã Manage GPT-OSS Models</h3>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># List installed GPT-OSS models</span>
super<span class="w"> </span>model<span class="w"> </span>list<span class="w"> </span><span class="p">|</span><span class="w"> </span>grep<span class="w"> </span>gpt-oss

<span class="c1"># Get detailed information</span>
super<span class="w"> </span>model<span class="w"> </span>info<span class="w"> </span>gpt-oss:20b
super<span class="w"> </span>model<span class="w"> </span>info<span class="w"> </span>openai/gpt-oss-120b

<span class="c1"># Test model performance</span>
super<span class="w"> </span>model<span class="w"> </span><span class="nb">test</span><span class="w"> </span>gpt-oss:20b<span class="w"> </span><span class="s2">&quot;Hello, how are you?&quot;</span>
</code></pre></div>
<h3 id="performance-recommendations">üéØ Performance Recommendations</h3>
<table>
<thead>
<tr>
<th>Use Case</th>
<th>Recommended Model</th>
<th>Hardware</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Quick responses</strong></td>
<td>GPT-OSS-20B</td>
<td>16GB+ RAM</td>
</tr>
<tr>
<td><strong>Complex tasks</strong></td>
<td>GPT-OSS-120B</td>
<td>H100 GPU</td>
</tr>
<tr>
<td><strong>Local development</strong></td>
<td>GPT-OSS-20B</td>
<td>16GB+ RAM</td>
</tr>
</tbody>
</table>
<h3 id="troubleshooting-gpt-oss">üîß Troubleshooting GPT-OSS</h3>
<div class="tabbed-set tabbed-alternate" data-tabs="2:1"><input checked="checked" id="__tabbed_2_1" name="__tabbed_2" type="radio" /><div class="tabbed-labels"><label for="__tabbed_2_1">Apple Silicon Mixed Precision Issues</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p><strong>Error:</strong> <code>error: 'mps.matmul' op detected operation with both F16 and BF16 operands which is not supported</code></p>
<p><strong>Solution:</strong>
```bash</p>
<h1 id="use-mlx-lm-backend-native-apple-silicon-support">Use MLX-LM backend (native Apple Silicon support)</h1>
</div>
</div>
</div>
<p>super model run lmstudio-community/gpt-oss-20b-MLX-8bit "prompt" --backend mlx</p>
<div class="language-text highlight"><pre><span></span><code># Or use Ollama backend (optimized format)
super model run gpt-oss:20b &quot;prompt&quot; --backend ollama
```
</code></pre></div>
<div class="tabbed-set tabbed-alternate" data-tabs="3:1"><input checked="checked" id="__tabbed_3_1" name="__tabbed_3" type="radio" /><div class="tabbed-labels"><label for="__tabbed_3_1">Model Not Found</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p><strong>Error:</strong> <code>Model not found</code> or <code>Model does not exist</code></p>
<p><strong>Solution:</strong>
```bash</p>
<h1 id="for-mlx-lm-apple-silicon">For MLX-LM (Apple Silicon)</h1>
</div>
</div>
</div>
<p>super model install lmstudio-community/gpt-oss-20b-MLX-8bit --backend mlx</p>
<div class="language-text highlight"><pre><span></span><code># For Ollama
ollama pull gpt-oss:20b
ollama pull gpt-oss:120b

# For HuggingFace
super model install openai/gpt-oss-20b --backend huggingface
super model install openai/gpt-oss-120b --backend huggingface
```
</code></pre></div>
<div class="tabbed-set tabbed-alternate" data-tabs="4:2"><input checked="checked" id="__tabbed_4_1" name="__tabbed_4" type="radio" /><input id="__tabbed_4_2" name="__tabbed_4" type="radio" /><div class="tabbed-labels"><label for="__tabbed_4_1">Out of Memory</label><label for="__tabbed_4_2">Server Connection Failed</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p><strong>Error:</strong> <code>CUDA out of memory</code> or <code>Not enough memory</code></p>
<p><strong>Solution:</strong>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Use smaller model</span>
super<span class="w"> </span>model<span class="w"> </span>install<span class="w"> </span>gpt-oss:20b<span class="w">  </span><span class="c1"># Instead of 120b</span>

<span class="c1"># Use CPU inference</span>
super<span class="w"> </span>model<span class="w"> </span>server<span class="w"> </span>huggingface<span class="w"> </span>openai/gpt-oss-20b<span class="w"> </span>--device<span class="w"> </span>cpu
</code></pre></div></p>
</div>
<div class="tabbed-block">
<p><strong>Error:</strong> <code>Connection refused</code> or <code>Cannot connect to server</code></p>
<p><strong>Solution:</strong>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Check Ollama server</span>
ollama<span class="w"> </span>serve

<span class="c1"># Check HuggingFace server</span>
super<span class="w"> </span>model<span class="w"> </span>server<span class="w"> </span>huggingface<span class="w"> </span>openai/gpt-oss-20b<span class="w"> </span>--port<span class="w"> </span><span class="m">8001</span>
</code></pre></div></p>
</div>
</div>
</div>
<h3 id="resources">üìö Resources</h3>
<ul>
<li><a href="https://huggingface.co/openai/gpt-oss-120b">GPT-OSS-120B Model</a> - HuggingFace repository</li>
<li><a href="https://huggingface.co/openai/gpt-oss-20b">GPT-OSS-20B Model</a> - HuggingFace repository</li>
<li><a href="https://ollama.com/library/gpt-oss">Ollama Library</a> - Ollama model library</li>
<li><a href="https://superoptix.ai">SuperOptiX Documentation</a> - Complete framework documentation</li>
<li><a href="https://dspy.ai">DSPy Framework</a> - Foundation framework</li>
</ul>
<h2 id="mlx-apple-silicon">üçé MLX (Apple Silicon)</h2>
<p><strong>MLX</strong> is Apple's native machine learning framework, offering blazing-fast inference on Apple Silicon Macs. <strong>MLX-LM v0.26.3</strong> now provides native support for GPT-OSS models!</p>
<div class="admonition tip">
<p class="admonition-title">Apple Silicon Only</p>
<p>MLX only works on Apple Silicon Macs (M1, M2, M3). If you're on Intel Mac, use Ollama instead.</p>
</div>
<h3 id="setup-mlx">üöÄ Setup MLX</h3>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Install MLX dependencies</span>
pip<span class="w"> </span>install<span class="w"> </span>mlx-lm<span class="o">==</span><span class="m">0</span>.26.3

<span class="c1"># Or install with SuperOptiX</span>
pip<span class="w"> </span>install<span class="w"> </span><span class="s2">&quot;superoptix[mlx]&quot;</span>
</code></pre></div>
<h3 id="install-mlx-models">üì¶ Install MLX Models</h3>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Install GPT-OSS models (native Apple Silicon support)</span>
super<span class="w"> </span>model<span class="w"> </span>install<span class="w"> </span>openai/gpt-oss-20b<span class="w"> </span>--backend<span class="w"> </span>mlx
super<span class="w"> </span>model<span class="w"> </span>install<span class="w"> </span>openai/gpt-oss-120b<span class="w"> </span>--backend<span class="w"> </span>mlx

<span class="c1"># Install popular MLX models</span>
super<span class="w"> </span>model<span class="w"> </span>install<span class="w"> </span>-b<span class="w"> </span>mlx<span class="w"> </span>mlx-community/phi-2
super<span class="w"> </span>model<span class="w"> </span>install<span class="w"> </span>-b<span class="w"> </span>mlx<span class="w"> </span>mlx-community/Llama-3.2-3B-Instruct-4bit
super<span class="w"> </span>model<span class="w"> </span>install<span class="w"> </span>-b<span class="w"> </span>mlx<span class="w"> </span>mlx-community/Mistral-7B-Instruct-v0.2-4bit
super<span class="w"> </span>model<span class="w"> </span>install<span class="w"> </span>-b<span class="w"> </span>mlx<span class="w"> </span>lmstudio-community/gpt-oss-20b-MLX-8bit
</code></pre></div>
<h3 id="start-mlx-servers">üñ•Ô∏è Start MLX Servers</h3>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Start MLX server on specific port</span>
super<span class="w"> </span>model<span class="w"> </span>server<span class="w"> </span>mlx<span class="w"> </span>phi-2<span class="w"> </span>--port<span class="w"> </span><span class="m">8000</span>
super<span class="w"> </span>model<span class="w"> </span>server<span class="w"> </span>mlx<span class="w"> </span>mlx-community/Llama-3.2-3B-Instruct-4bit<span class="w"> </span>--port<span class="w"> </span><span class="m">8000</span>
</code></pre></div>
<p><strong>Example Output:</strong>
<div class="language-text highlight"><pre><span></span><code>üçé MLX Local Server
Starting MLX server for mlx-community_Llama-3.2-3B-Instruct-4bit on port 8000...
üöÄ Starting MLX server...
üì° Server will be available at: http://localhost:8000
üí° Use this URL in your playbook&#39;s api_base configuration
üîß Manual server startup command:
   python -m mlx_lm.server --model mlx-community_Llama-3.2-3B-Instruct-4bit --port 8000
üìã Example playbook configuration:
   language_model:
     provider: mlx
     model: mlx-community_Llama-3.2-3B-Instruct-4bit
     api_base: http://localhost:8000
üîÑ Executing: /path/to/python -m mlx_lm.server --model mlx-community_Llama-3.2-3B-Instruct-4bit --port 8000
‚è≥ Server is starting... (Press Ctrl+C to stop)
</code></pre></div></p>
<h3 id="manage-mlx-models">üìã Manage MLX Models</h3>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># List MLX models</span>
super<span class="w"> </span>model<span class="w"> </span>list<span class="w"> </span>--backend<span class="w"> </span>mlx
</code></pre></div>
<p><strong>Example Output:</strong>
<div class="language-text highlight"><pre><span></span><code>                    üöÄ SuperOptiX Model Intelligence - 1 models                     
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ Model                                    ‚îÉ Backend ‚îÉ    Status    ‚îÉ Size  ‚îÉ Task ‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ mlx-community_Llama-3.2-3B-Instruct-4bit ‚îÇ üçé mlx  ‚îÇ installed ‚îÇ small ‚îÇ chat ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre></div></p>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Get model information</span>
super<span class="w"> </span>model<span class="w"> </span>info<span class="w"> </span>mlx-community/phi-2
super<span class="w"> </span>model<span class="w"> </span>info<span class="w"> </span>mlx-community_Llama-3.2-3B-Instruct-4bit

<span class="c1"># Models are ready to use with SuperOptiX agents</span>
</code></pre></div>
<h2 id="lm-studio">üéÆ LM Studio</h2>
<p><strong>LM Studio</strong> provides a user-friendly interface for running local models, especially popular on Windows.</p>
<h3 id="setup-lm-studio">üöÄ Setup LM Studio</h3>
<ol>
<li><strong>Download LM Studio</strong> from <a href="https://lmstudio.ai">https://lmstudio.ai</a></li>
<li><strong>Install and launch</strong> LM Studio</li>
<li><strong>Download a model</strong> through the interface</li>
<li><strong>Start the server</strong> (default port: 1234)</li>
</ol>
<h3 id="install-models-with-superoptix_1">üì¶ Install Models with SuperOptiX</h3>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Install models (use the name from LM Studio)</span>
super<span class="w"> </span>model<span class="w"> </span>install<span class="w"> </span>-b<span class="w"> </span>lmstudio<span class="w"> </span>llama-3.2-1b-instruct
super<span class="w"> </span>model<span class="w"> </span>install<span class="w"> </span>-b<span class="w"> </span>lmstudio<span class="w"> </span>llama-3.2-3b
super<span class="w"> </span>model<span class="w"> </span>install<span class="w"> </span>-b<span class="w"> </span>lmstudio<span class="w"> </span>your-model-name
</code></pre></div>
<h3 id="start-lm-studio-servers">üñ•Ô∏è Start LM Studio Servers</h3>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Start server with specific model</span>
super<span class="w"> </span>model<span class="w"> </span>server<span class="w"> </span>lmstudio<span class="w"> </span>llama-3.2-1b-instruct<span class="w"> </span>--port<span class="w"> </span><span class="m">1234</span>
super<span class="w"> </span>model<span class="w"> </span>server<span class="w"> </span>lmstudio<span class="w"> </span>llama-3.2-3b<span class="w"> </span>--port<span class="w"> </span><span class="m">1234</span>
</code></pre></div>
<p><strong>Example Output:</strong>
<div class="language-text highlight"><pre><span></span><code>üéÆ LM Studio Local Server
Starting LM Studio server for llama-3.2-1b-instruct on port 1234...
üöÄ Starting LM Studio server...
üì° Server will be available at: http://localhost:1234
üí° Use this URL in your playbook&#39;s api_base configuration
üîß Manual server startup command:
   # Start server in LM Studio app first, then connect
üìã Example playbook configuration:
   language_model:
     provider: lmstudio
     model: llama-3.2-1b-instruct
     api_base: http://localhost:1234
‚è≥ Server is starting... (Press Ctrl+C to stop)
</code></pre></div></p>
<h3 id="manage-lm-studio-models">üìã Manage LM Studio Models</h3>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># List LM Studio models</span>
super<span class="w"> </span>model<span class="w"> </span>list<span class="w"> </span>--backend<span class="w"> </span>lmstudio
</code></pre></div>
<p><strong>Example Output:</strong>
<div class="language-text highlight"><pre><span></span><code>                  üöÄ SuperOptiX Model Intelligence - 3 models                  
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ Model                          ‚îÉ   Backend   ‚îÉ    Status    ‚îÉ  Size  ‚îÉ Task ‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ llama-3.2-1b-instruct          ‚îÇ üéÆ lmstudio ‚îÇ installed ‚îÇ small  ‚îÇ chat ‚îÇ
‚îÇ llama-3.3-70b-instruct         ‚îÇ üéÆ lmstudio ‚îÇ installed ‚îÇ large  ‚îÇ chat ‚îÇ
‚îÇ llama-4-scout-17b-16e-instruct ‚îÇ üéÆ lmstudio ‚îÇ installed ‚îÇ medium ‚îÇ chat ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre></div></p>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Get model information</span>
super<span class="w"> </span>model<span class="w"> </span>info<span class="w"> </span>llama-3.2-1b-instruct

<span class="c1"># Models are ready to use with SuperOptiX agents</span>
</code></pre></div>
<h2 id="huggingface">ü§ó HuggingFace</h2>
<p><strong>HuggingFace</strong> offers access to thousands of models, perfect for advanced users who want maximum flexibility.</p>
<h3 id="setup-huggingface">üöÄ Setup HuggingFace</h3>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Install HuggingFace dependencies</span>
pip<span class="w"> </span>install<span class="w"> </span>transformers<span class="w"> </span>torch<span class="w"> </span>fastapi<span class="w"> </span>uvicorn

<span class="c1"># Or install with SuperOptiX</span>
pip<span class="w"> </span>install<span class="w"> </span><span class="s2">&quot;superoptix[huggingface]&quot;</span>
</code></pre></div>
<h3 id="install-huggingface-models">üì¶ Install HuggingFace Models</h3>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Install popular models</span>
super<span class="w"> </span>model<span class="w"> </span>install<span class="w"> </span>-b<span class="w"> </span>huggingface<span class="w"> </span>microsoft/Phi-4
super<span class="w"> </span>model<span class="w"> </span>install<span class="w"> </span>-b<span class="w"> </span>huggingface<span class="w"> </span>microsoft/DialoGPT-small
super<span class="w"> </span>model<span class="w"> </span>install<span class="w"> </span>-b<span class="w"> </span>huggingface<span class="w"> </span>microsoft/DialoGPT-medium
super<span class="w"> </span>model<span class="w"> </span>install<span class="w"> </span>-b<span class="w"> </span>huggingface<span class="w"> </span>meta-llama/Llama-2-7b-chat-hf
</code></pre></div>
<h3 id="start-huggingface-servers">üñ•Ô∏è Start HuggingFace Servers</h3>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Start server with specific model</span>
super<span class="w"> </span>model<span class="w"> </span>server<span class="w"> </span>huggingface<span class="w"> </span>microsoft/Phi-4<span class="w"> </span>--port<span class="w"> </span><span class="m">8001</span>
super<span class="w"> </span>model<span class="w"> </span>server<span class="w"> </span>huggingface<span class="w"> </span>microsoft/DialoGPT-small<span class="w"> </span>--port<span class="w"> </span><span class="m">8001</span>
super<span class="w"> </span>model<span class="w"> </span>server<span class="w"> </span>huggingface<span class="w"> </span>microsoft/DialoGPT-medium<span class="w"> </span>--port<span class="w"> </span><span class="m">8001</span>
</code></pre></div>
<p><strong>Example Output:</strong>
<div class="language-text highlight"><pre><span></span><code>ü§ó HuggingFace Local Server
Starting HuggingFace server for microsoft/DialoGPT-small on port 8002...
üöÄ Starting HuggingFace server...
üì° Server will be available at: http://localhost:8002
üí° Use this URL in your playbook&#39;s api_base configuration
üîß Manual server startup command:
   python -m superoptix.models.backends.huggingface_server microsoft/DialoGPT-small --port 8002
üìã Example playbook configuration:
   language_model:
     provider: huggingface
     model: microsoft/DialoGPT-small
     api_base: http://localhost:8002
Device set to use cpu
INFO:     Started server process [4652]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://127.0.0.1:8002 (Press CTRL+C to quit)
</code></pre></div></p>
<h3 id="manage-huggingface-models">üìã Manage HuggingFace Models</h3>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># List HuggingFace models</span>
super<span class="w"> </span>model<span class="w"> </span>list<span class="w"> </span>--backend<span class="w"> </span>huggingface
</code></pre></div>
<p><strong>Example Output:</strong>
<div class="language-text highlight"><pre><span></span><code>                üöÄ SuperOptiX Model Intelligence - 2 models                
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ Model                    ‚îÉ    Backend     ‚îÉ    Status    ‚îÉ Size  ‚îÉ Task ‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ microsoft/DialoGPT-small ‚îÇ ü§ó huggingface ‚îÇ installed ‚îÇ small ‚îÇ chat ‚îÇ
‚îÇ microsoft/Phi-4          ‚îÇ ü§ó huggingface ‚îÇ installed ‚îÇ small ‚îÇ chat ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre></div></p>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Get model information</span>
super<span class="w"> </span>model<span class="w"> </span>info<span class="w"> </span>microsoft/Phi-4
super<span class="w"> </span>model<span class="w"> </span>info<span class="w"> </span>microsoft/DialoGPT-small

<span class="c1"># Models are ready to use with SuperOptiX agents</span>
</code></pre></div>
<h2 id="model-management-commands">üéØ Model Management Commands</h2>
<h3 id="server-commands">üñ•Ô∏è Server Commands</h3>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Get help for server commands</span>
super<span class="w"> </span>model<span class="w"> </span>server<span class="w"> </span>--help
</code></pre></div>
<p><strong>Example Output:</strong>
<div class="language-text highlight"><pre><span></span><code>usage: super model server [-h] [--port PORT] {mlx,huggingface,lmstudio} model_name

üöÄ Start local model servers for MLX, HuggingFace, or LM Studio. Examples: 
super model server mlx mlx-community/Llama-3.2-3B-Instruct-4bit 
super model server huggingface microsoft/DialoGPT-small --port 8001
super model server lmstudio llama-3.2-1b-instruct 

Backends: 
mlx Apple Silicon optimized (default: port 8000) 
huggingface Transformers models (default: port 8001) 
lmstudio Desktop app models (default: port 1234) 

Note: Ollama servers use &#39;ollama serve&#39; command separately.

positional arguments:
  {mlx,huggingface,lmstudio}  Backend type
  model_name                   Model name to start server for

options:
  -h, --help                   show this help message and exit
  --port PORT, -p PORT         Port to run server on
</code></pre></div></p>
<h3 id="list-and-explore-models">üìã List and Explore Models</h3>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># List all installed models</span>
super<span class="w"> </span>model<span class="w"> </span>list
</code></pre></div>
<p><strong>Example Output:</strong>
<div class="language-text highlight"><pre><span></span><code>                           üöÄ SuperOptiX Model Intelligence - 9 models                   
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ Model                                    ‚îÉ    Backend     ‚îÉ    Status    ‚îÉ  Size   ‚îÉ   Task    ‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ llama-3.2-1b-instruct                    ‚îÇ  üéÆ lmstudio   ‚îÇ installed ‚îÇ  small  ‚îÇ   chat    ‚îÇ
‚îÇ llama-3.3-70b-instruct                   ‚îÇ  üéÆ lmstudio   ‚îÇ installed ‚îÇ  large  ‚îÇ   chat    ‚îÇ
‚îÇ llama-4-scout-17b-16e-instruct           ‚îÇ  üéÆ lmstudio   ‚îÇ installed ‚îÇ medium  ‚îÇ   chat    ‚îÇ
‚îÇ llama3.1:8b                              ‚îÇ   ü¶ô ollama    ‚îÇ installed ‚îÇ medium  ‚îÇ   chat    ‚îÇ
‚îÇ llama3.2:1b                              ‚îÇ   ü¶ô ollama    ‚îÇ installed ‚îÇ  tiny   ‚îÇ   chat    ‚îÇ
‚îÇ microsoft/DialoGPT-small                 ‚îÇ ü§ó huggingface ‚îÇ installed ‚îÇ  small  ‚îÇ   chat    ‚îÇ
‚îÇ microsoft/Phi-4                          ‚îÇ ü§ó huggingface ‚îÇ installed ‚îÇ  small  ‚îÇ   chat    ‚îÇ
‚îÇ mlx-community_Llama-3.2-3B-Instruct-4bit ‚îÇ     üçé mlx     ‚îÇ installed ‚îÇ  small  ‚îÇ   chat    ‚îÇ
‚îÇ nomic-embed-text:latest                  ‚îÇ   ü¶ô ollama    ‚îÇ installed ‚îÇ Unknown ‚îÇ embedding ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

üîç Discover more models: super model discover
üì• Install a model: super model install &lt;model_name&gt;
</code></pre></div></p>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># List all available models (including uninstalled)</span>
super<span class="w"> </span>model<span class="w"> </span>list<span class="w"> </span>--all

<span class="c1"># Filter by backend</span>
super<span class="w"> </span>model<span class="w"> </span>list<span class="w"> </span>--backend<span class="w"> </span>ollama
super<span class="w"> </span>model<span class="w"> </span>list<span class="w"> </span>--backend<span class="w"> </span>mlx
super<span class="w"> </span>model<span class="w"> </span>list<span class="w"> </span>--backend<span class="w"> </span>lmstudio
super<span class="w"> </span>model<span class="w"> </span>list<span class="w"> </span>--backend<span class="w"> </span>huggingface

<span class="c1"># Verbose information</span>
super<span class="w"> </span>model<span class="w"> </span>list<span class="w"> </span>--verbose
</code></pre></div>
<h3 id="get-model-information">üìä Get Model Information</h3>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Get detailed model info</span>
super<span class="w"> </span>model<span class="w"> </span>info<span class="w"> </span>llama3.2:3b
super<span class="w"> </span>model<span class="w"> </span>info<span class="w"> </span>mlx-community/phi-2
super<span class="w"> </span>model<span class="w"> </span>info<span class="w"> </span>microsoft/Phi-4
super<span class="w"> </span>model<span class="w"> </span>info<span class="w"> </span>llama-3.2-1b-instruct
</code></pre></div>
<h2 id="choose-your-setup">üéØ Choose Your Setup</h2>
<h3 id="beginner-recommended">üöÄ <strong>Beginner (Recommended)</strong></h3>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Install Ollama</span>
curl<span class="w"> </span>-fsSL<span class="w"> </span>https://ollama.ai/install.sh<span class="w"> </span><span class="p">|</span><span class="w"> </span>sh

<span class="c1"># Install SuperOptiX</span>
pip<span class="w"> </span>install<span class="w"> </span>superoptix

<span class="c1"># Install a model</span>
super<span class="w"> </span>model<span class="w"> </span>install<span class="w"> </span>llama3.2:3b

<span class="c1"># Models are ready to use with SuperOptiX agents</span>
</code></pre></div>
<h3 id="apple-silicon-user">üçé <strong>Apple Silicon User</strong></h3>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Install MLX dependencies</span>
pip<span class="w"> </span>install<span class="w"> </span>mlx-lm

<span class="c1"># Install SuperOptiX</span>
pip<span class="w"> </span>install<span class="w"> </span>superoptix

<span class="c1"># Install MLX model</span>
super<span class="w"> </span>model<span class="w"> </span>install<span class="w"> </span>-b<span class="w"> </span>mlx<span class="w"> </span>mlx-community/phi-2

<span class="c1"># Start server</span>
super<span class="w"> </span>model<span class="w"> </span>server<span class="w"> </span>mlx<span class="w"> </span>phi-2<span class="w"> </span>--port<span class="w"> </span><span class="m">8000</span>

<span class="c1"># Models are ready to use with SuperOptiX agents</span>
</code></pre></div>
<h3 id="windows-user">üéÆ <strong>Windows User</strong></h3>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Install LM Studio from https://lmstudio.ai</span>
<span class="c1"># Download a model in LM Studio</span>
<span class="c1"># Start server in LM Studio</span>

<span class="c1"># Install SuperOptiX</span>
pip<span class="w"> </span>install<span class="w"> </span>superoptix

<span class="c1"># Connect to LM Studio</span>
super<span class="w"> </span>model<span class="w"> </span>server<span class="w"> </span>lmstudio<span class="w"> </span>your-model-name<span class="w"> </span>--port<span class="w"> </span><span class="m">1234</span>

<span class="c1"># Models are ready to use with SuperOptiX agents</span>
</code></pre></div>
<h3 id="advanced-user">ü§ó <strong>Advanced User</strong></h3>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Install HuggingFace dependencies</span>
pip<span class="w"> </span>install<span class="w"> </span>transformers<span class="w"> </span>torch<span class="w"> </span>fastapi<span class="w"> </span>uvicorn

<span class="c1"># Install SuperOptiX</span>
pip<span class="w"> </span>install<span class="w"> </span>superoptix

<span class="c1"># Install HuggingFace model</span>
super<span class="w"> </span>model<span class="w"> </span>install<span class="w"> </span>-b<span class="w"> </span>huggingface<span class="w"> </span>microsoft/Phi-4

<span class="c1"># Start server</span>
super<span class="w"> </span>model<span class="w"> </span>server<span class="w"> </span>huggingface<span class="w"> </span>microsoft/Phi-4<span class="w"> </span>--port<span class="w"> </span><span class="m">8001</span>

<span class="c1"># Models are ready to use with SuperOptiX agents</span>
</code></pre></div>
<h2 id="advanced-configuration">üîß Advanced Configuration</h2>
<h3 id="multiple-servers">üåê Multiple Servers</h3>
<p>Run multiple models simultaneously:</p>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Terminal 1: Ollama model</span>
<span class="c1"># Models are ready to use with SuperOptiX agents</span>

<span class="c1"># Terminal 2: MLX model (Apple Silicon)</span>
super<span class="w"> </span>model<span class="w"> </span>server<span class="w"> </span>mlx<span class="w"> </span>phi-2<span class="w"> </span>--port<span class="w"> </span><span class="m">8000</span>
<span class="c1"># Models are ready to use with SuperOptiX agents</span>

<span class="c1"># Terminal 3: HuggingFace model</span>
super<span class="w"> </span>model<span class="w"> </span>server<span class="w"> </span>huggingface<span class="w"> </span>microsoft/Phi-4<span class="w"> </span>--port<span class="w"> </span><span class="m">8001</span>
<span class="c1"># Models are ready to use with SuperOptiX agents</span>

<span class="c1"># Terminal 4: LM Studio model</span>
super<span class="w"> </span>model<span class="w"> </span>server<span class="w"> </span>lmstudio<span class="w"> </span>llama-3.2-1b-instruct<span class="w"> </span>--port<span class="w"> </span><span class="m">1234</span>
<span class="c1"># Models are ready to use with SuperOptiX agents</span>
</code></pre></div>
<h2 id="troubleshooting">üö® Troubleshooting</h2>
<h3 id="common-issues">Common Issues</h3>
<div class="tabbed-set tabbed-alternate" data-tabs="5:7"><input checked="checked" id="__tabbed_5_1" name="__tabbed_5" type="radio" /><input id="__tabbed_5_2" name="__tabbed_5" type="radio" /><input id="__tabbed_5_3" name="__tabbed_5" type="radio" /><input id="__tabbed_5_4" name="__tabbed_5" type="radio" /><input id="__tabbed_5_5" name="__tabbed_5" type="radio" /><input id="__tabbed_5_6" name="__tabbed_5" type="radio" /><input id="__tabbed_5_7" name="__tabbed_5" type="radio" /><div class="tabbed-labels"><label for="__tabbed_5_1">Model Not Found</label><label for="__tabbed_5_2">Server Connection Failed</label><label for="__tabbed_5_3">Port Already in Use</label><label for="__tabbed_5_4">Apple Silicon Required</label><label for="__tabbed_5_5">Missing Python Packages</label><label for="__tabbed_5_6">Missing CLI Tools</label><label for="__tabbed_5_7">Authentication Errors</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p><strong>Error:</strong> <code>Model not found</code> or <code>Model does not exist</code></p>
<p><strong>Solution:</strong>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Check available models</span>
super<span class="w"> </span>model<span class="w"> </span>list<span class="w"> </span>--all

<span class="c1"># Use correct model name</span>
super<span class="w"> </span>model<span class="w"> </span>install<span class="w"> </span>llama3.2:3b<span class="w">  </span><span class="c1"># Correct</span>
super<span class="w"> </span>model<span class="w"> </span>install<span class="w"> </span>llama3.2<span class="w">     </span><span class="c1"># Wrong</span>
</code></pre></div></p>
</div>
<div class="tabbed-block">
<p><strong>Error:</strong> <code>Connection refused</code> or <code>Cannot connect to server</code></p>
<p><strong>Solution:</strong>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Check if server is running</span>
<span class="c1"># For Ollama: ollama serve</span>
<span class="c1"># For MLX: super model server mlx phi-2 --port 8000</span>
<span class="c1"># For LM Studio: Start in LM Studio app</span>
<span class="c1"># For HuggingFace: super model server huggingface model --port 8001</span>
</code></pre></div></p>
</div>
<div class="tabbed-block">
<p><strong>Error:</strong> <code>Address already in use</code></p>
<p><strong>Solution:</strong>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Use different port</span>
super<span class="w"> </span>model<span class="w"> </span>server<span class="w"> </span>mlx<span class="w"> </span>phi-2<span class="w"> </span>--port<span class="w"> </span><span class="m">8001</span>
super<span class="w"> </span>model<span class="w"> </span>server<span class="w"> </span>huggingface<span class="w"> </span>microsoft/Phi-4<span class="w"> </span>--port<span class="w"> </span><span class="m">8002</span>
</code></pre></div></p>
</div>
<div class="tabbed-block">
<p><strong>Error:</strong> <code>MLX requires Apple Silicon</code></p>
<p><strong>Solution:</strong>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Use Ollama instead</span>
super<span class="w"> </span>model<span class="w"> </span>install<span class="w"> </span>llama3.2:3b
super<span class="w"> </span>model<span class="w"> </span>dspy<span class="w"> </span>ollama/llama3.2:3b
</code></pre></div></p>
</div>
<div class="tabbed-block">
<p><strong>Error:</strong> <code>ModuleNotFoundError: No module named 'mlx_lm'</code> or <code>ModuleNotFoundError: No module named 'transformers'</code></p>
<p><strong>Solution:</strong>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Install MLX dependencies</span>
pip<span class="w"> </span>install<span class="w"> </span>mlx-lm

<span class="c1"># Install HuggingFace dependencies</span>
pip<span class="w"> </span>install<span class="w"> </span>transformers<span class="w"> </span>torch<span class="w"> </span>fastapi<span class="w"> </span>uvicorn

<span class="c1"># Or install with SuperOptiX extras</span>
pip<span class="w"> </span>install<span class="w"> </span><span class="s2">&quot;superoptix[mlx]&quot;</span>
pip<span class="w"> </span>install<span class="w"> </span><span class="s2">&quot;superoptix[huggingface]&quot;</span>
</code></pre></div></p>
</div>
<div class="tabbed-block">
<p><strong>Error:</strong> <code>Command 'ollama' not found</code> or <code>Command 'lms' not found</code></p>
<p><strong>Solution:</strong>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Install Ollama</span>
curl<span class="w"> </span>-fsSL<span class="w"> </span>https://ollama.ai/install.sh<span class="w"> </span><span class="p">|</span><span class="w"> </span>sh

<span class="c1"># Install LM Studio</span>
<span class="c1"># Download from https://lmstudio.ai</span>
<span class="c1"># Or use winget on Windows:</span>
winget<span class="w"> </span>install<span class="w"> </span>LMStudio.LMStudio

<span class="c1"># Verify installation</span>
ollama<span class="w"> </span>--version
lms<span class="w"> </span>--version
</code></pre></div></p>
</div>
<div class="tabbed-block">
<p><strong>Error:</strong> <code>401 Unauthorized</code> or <code>Repository Not Found</code></p>
<p><strong>Solution:</strong>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># For HuggingFace models, login:</span>
huggingface-cli<span class="w"> </span>login

<span class="c1"># For MLX models, ensure you have access:</span>
<span class="c1"># Some models require accepting terms on HuggingFace website</span>

<span class="c1"># Use public models instead:</span>
super<span class="w"> </span>model<span class="w"> </span>install<span class="w"> </span>-b<span class="w"> </span>mlx<span class="w"> </span>mlx-community/phi-2
super<span class="w"> </span>model<span class="w"> </span>install<span class="w"> </span>-b<span class="w"> </span>huggingface<span class="w"> </span>microsoft/Phi-4
</code></pre></div></p>
</div>
</div>
</div>
<h2 id="next-steps">üéâ Next Steps</h2>
<p>Now that you have your local models set up:</p>
<ol>
<li><strong>üöÄ <a href="../quick-start/">Quick Start Guide</a></strong> - Build your first agent with local models</li>
<li><strong>ü§ñ <a href="../tutorials/genies-agent/">Create Your First Genies Agent</a></strong> - Step-by-step tutorial</li>
<li><strong>üè™ <a href="../guides/marketplace.md">Marketplace</a></strong> - Discover pre-built agents</li>
<li><strong>üîç <a href="../guides/model-intelligence.md">Model Intelligence Guide</a></strong> - Advanced model management</li>
</ol>
<h2 id="need-help">üí¨ Need Help?</h2>
<ul>
<li><strong>üìñ <a href="../">Documentation</a></strong> - Comprehensive guides</li>
<li><strong>üêõ <a href="https://support.super-agentic.ai">Support Portal</a></strong> - Report bugs</li>
</ul>
<hr />
<div style="background: linear-gradient(90deg, #ede9fe, #fbcfe8, #fef3c7, #fdf6e3, #ede9fe); border-radius: 18px; padding: 2.2rem 1.2rem; margin: 2.2rem 0; box-shadow: 0 4px 24px 0 rgba(124,58,237,0.10);">
<h2 style="margin-top:0;">ü§ñ Ready to Run Local Models?</h2>
</div>

<h2 id="huggingface_1">ü§ó HuggingFace</h2>
<p><strong>HuggingFace</strong> offers access to thousands of models, perfect for advanced users who want maximum flexibility.</p>
<h3 id="setup-huggingface_1">üöÄ Setup HuggingFace</h3>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Install HuggingFace dependencies</span>
pip<span class="w"> </span>install<span class="w"> </span>transformers<span class="w"> </span>torch<span class="w"> </span>fastapi<span class="w"> </span>uvicorn

<span class="c1"># Or install with SuperOptiX</span>
pip<span class="w"> </span>install<span class="w"> </span><span class="s2">&quot;superoptix[huggingface]&quot;</span>
</code></pre></div>
<h3 id="install-huggingface-models_1">üì¶ Install HuggingFace Models</h3>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Install popular models</span>
super<span class="w"> </span>model<span class="w"> </span>install<span class="w"> </span>-b<span class="w"> </span>huggingface<span class="w"> </span>microsoft/Phi-4
super<span class="w"> </span>model<span class="w"> </span>install<span class="w"> </span>-b<span class="w"> </span>huggingface<span class="w"> </span>microsoft/DialoGPT-small
super<span class="w"> </span>model<span class="w"> </span>install<span class="w"> </span>-b<span class="w"> </span>huggingface<span class="w"> </span>microsoft/DialoGPT-medium
super<span class="w"> </span>model<span class="w"> </span>install<span class="w"> </span>-b<span class="w"> </span>huggingface<span class="w"> </span>meta-llama/Llama-2-7b-chat-hf
</code></pre></div>
<h3 id="start-huggingface-servers_1">üñ•Ô∏è Start HuggingFace Servers</h3>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Start server with specific model</span>
super<span class="w"> </span>model<span class="w"> </span>server<span class="w"> </span>huggingface<span class="w"> </span>microsoft/Phi-4<span class="w"> </span>--port<span class="w"> </span><span class="m">8001</span>
super<span class="w"> </span>model<span class="w"> </span>server<span class="w"> </span>huggingface<span class="w"> </span>microsoft/DialoGPT-small<span class="w"> </span>--port<span class="w"> </span><span class="m">8001</span>
super<span class="w"> </span>model<span class="w"> </span>server<span class="w"> </span>huggingface<span class="w"> </span>microsoft/DialoGPT-medium<span class="w"> </span>--port<span class="w"> </span><span class="m">8001</span>
</code></pre></div>
<p><strong>Example Output:</strong>
<div class="language-text highlight"><pre><span></span><code>ü§ó HuggingFace Local Server
Starting HuggingFace server for microsoft/DialoGPT-small on port 8002...
üöÄ Starting HuggingFace server...
üì° Server will be available at: http://localhost:8002
üí° Use this URL in your playbook&#39;s api_base configuration
üîß Manual server startup command:
   python -m superoptix.models.backends.huggingface_server microsoft/DialoGPT-small --port 8002
üìã Example playbook configuration:
   language_model:
     provider: huggingface
     model: microsoft/DialoGPT-small
     api_base: http://localhost:8002
Device set to use cpu
INFO:     Started server process [4652]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://127.0.0.1:8002 (Press CTRL+C to quit)
</code></pre></div></p>
<h3 id="manage-huggingface-models_1">üìã Manage HuggingFace Models</h3>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># List HuggingFace models</span>
super<span class="w"> </span>model<span class="w"> </span>list<span class="w"> </span>--backend<span class="w"> </span>huggingface
</code></pre></div>
<p><strong>Example Output:</strong>
<div class="language-text highlight"><pre><span></span><code>                üöÄ SuperOptiX Model Intelligence - 2 models                
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ Model                    ‚îÉ    Backend     ‚îÉ    Status    ‚îÉ Size  ‚îÉ Task ‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ microsoft/DialoGPT-small ‚îÇ ü§ó huggingface ‚îÇ installed ‚îÇ small ‚îÇ chat ‚îÇ
‚îÇ microsoft/Phi-4          ‚îÇ ü§ó huggingface ‚îÇ installed ‚îÇ small ‚îÇ chat ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre></div></p>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Get model information</span>
super<span class="w"> </span>model<span class="w"> </span>info<span class="w"> </span>microsoft/Phi-4
super<span class="w"> </span>model<span class="w"> </span>info<span class="w"> </span>microsoft/DialoGPT-small

<span class="c1"># Models are ready to use with SuperOptiX agents</span>
</code></pre></div>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright ¬© 2025 Superagentic AI. Made with ‚ù§Ô∏è for the Agentic AI community.
    </div>
  
  
</div>
      
        
<div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/SuperagenticAI" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://x.com/SuperagenticAI" target="_blank" rel="noopener" title="x.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M459.4 151.7c.3 4.5.3 9.1.3 13.6 0 138.7-105.6 298.6-298.6 298.6-59.5 0-114.7-17.2-161.1-47.1 8.4 1 16.6 1.3 25.3 1.3 49.1 0 94.2-16.6 130.3-44.8-46.1-1-84.8-31.2-98.1-72.8 6.5 1 13 1.6 19.8 1.6 9.4 0 18.8-1.3 27.6-3.6-48.1-9.7-84.1-52-84.1-103v-1.3c14 7.8 30.2 12.7 47.4 13.3-28.3-18.8-46.8-51-46.8-87.4 0-19.5 5.2-37.4 14.3-53C87.4 130.8 165 172.4 252.1 176.9c-1.6-7.8-2.6-15.9-2.6-24C249.5 95.1 296.3 48 354.4 48c30.2 0 57.5 12.7 76.7 33.1 23.7-4.5 46.5-13.3 66.6-25.3-7.8 24.4-24.4 44.8-46.1 57.8 21.1-2.3 41.6-8.1 60.4-16.2-14.3 20.8-32.2 39.3-52.6 54.3"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://www.linkedin.com/company/superagenticai" target="_blank" rel="noopener" title="www.linkedin.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zM102.2 96a38.5 38.5 0 1 1 0 77 38.5 38.5 0 1 1 0-77m282.1 320h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "..", "features": ["navigation.instant.prefetch", "navigation.tracking", "navigation.path", "navigation.top", "search.suggest", "search.highlight", "search.share", "content.code.copy", "content.code.annotate", "content.tabs.link"], "search": "../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.79ae519e.min.js"></script>
      
        <script src="https://unpkg.com/mermaid@10/dist/mermaid.min.js"></script>
      
        <script src="../javascripts/extra.js"></script>
      
    
  </body>
</html>