
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="AI Agent Development Framework: Evaluation-First and Optimization-Core.">
      
      
        <meta name="author" content="SuperagenticAI">
      
      
        <link rel="canonical" href="https://docs.super-agentic.ai/guides/model-management/">
      
      
        <link rel="prev" href="../conversational-interface/">
      
      
        <link rel="next" href="../model-intelligence/">
      
      
        
      
      
      <link rel="icon" href="../../favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.1">
    
    
      
        <title>üß† Model Management - SUPEROPTIX AI</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.484c7ddc.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Inter:300,300i,400,400i,700,700i%7CFira+Code:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Inter";--md-code-font:"Fira Code"}</style>
      
    
    
      <link rel="stylesheet" href="../../stylesheets/extra.css?v=24.0">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="grey" data-md-color-accent="purple">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#model-management-guide" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="SUPEROPTIX AI" class="md-header__button md-logo" aria-label="SUPEROPTIX AI" data-md-component="logo">
      
  <img src="../../logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            SUPEROPTIX AI
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              üß† Model Management
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="grey" data-md-color-accent="purple"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="grey" data-md-color-accent="purple"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="SUPEROPTIX AI" class="md-nav__button md-logo" aria-label="SUPEROPTIX AI" data-md-component="logo">
      
  <img src="../../logo.png" alt="logo">

    </a>
    SUPEROPTIX AI
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üè† Home
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    üöÄ Get Started
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    üöÄ Get Started
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../introduction/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üìñ Introduction
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../quick-start/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üöÄ Quick Start
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../golden-workflow/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ‚≠ê Golden Workflow
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorials/multi-framework-quickstart/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üåê Multi-Framework Quick Start
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../setup/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ‚öôÔ∏è Setup & Installation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../troubleshooting-by-symptom/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üõ†Ô∏è Troubleshooting by Symptom
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../llm-setup/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üß† LLM Setup
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../environment-setup/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üèóÔ∏è Environment Setup
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../project-structure/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üìÅ Project Structure
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_10" >
        
          
          <label class="md-nav__link" for="__nav_2_10" id="__nav_2_10_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    üéì Tutorials
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_10_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_10">
            <span class="md-nav__icon md-icon"></span>
            
  
    üéì Tutorials
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorials/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üìö Tutorials Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorials/openai-sdk-gepa-optimization/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üîß OpenAI SDK + GEPA Optimization
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    üî¨ Frameworks
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    üî¨ Frameworks
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üìö Frameworks Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../multi-framework/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üåê Comparison
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../framework-feature-matrix/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üìä Feature Matrix
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../openai-sdk-integration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ü§ñ OpenAI SDK
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../claude-sdk-integration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üß† Claude Agent SDK
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pydantic-ai-integration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üêç Pydantic AI
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pydantic-ai-mcp-demo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üêç Pydantic AI MCP Demo
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../crewai-integration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üë• CrewAI
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../crewai-task-optimization/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ‚ö° CrewAI Advanced
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../google-adk-integration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üîÆ Google ADK
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../microsoft-framework-integration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üè¢ Microsoft (Legacy)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../deepagents-integration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üåä DeepAgents
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    üìù SuperSpec
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    üìù SuperSpec
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../superspec/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üìù SuperSpec Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../superspec-dsl-reference/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üìó DSL Reference
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../superspec-dsl-examples/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üìô DSL Examples
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../superspec-agent-building/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üèóÔ∏è Agent Building
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../superspec-configuration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ‚öôÔ∏è Configuration
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../superspec-context-engineering/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üß† Context Engineering
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    üõ†Ô∏è Build
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            
  
    üõ†Ô∏è Build
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../agent-patterns/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üé® Agent Patterns
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../agent-discovery/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üîç Agent Discovery
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../agent-development/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ü§ñ Agent Development
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tool-development/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üîß Tool Development
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../technical-architecture/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üèõÔ∏è Technical Architecture
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Evaluate
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            
  
    Evaluate
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../evaluation-testing/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Evaluation & Testing
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bdd/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üé≠ RSpec-Style BDD Testing
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" >
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    üéØ Agent Optimization
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            
  
    üéØ Agent Optimization
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../agent-optimization/overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üìñ Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../agent-optimization/prompts/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üí¨ Prompt Optimization
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../agent-optimization/rag/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üîç RAG Optimization
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../agent-optimization/tools/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üõ†Ô∏è Tool Optimization
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../agent-optimization/memory/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üß† Memory Optimization
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../agent-optimization/protocols/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üîå Protocol Optimization (MCP)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../agent-optimization/datasets/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üìä Dataset-Driven Optimization
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../agent-optimization/full-stack-example/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üéØ Full-Stack Example
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8" >
        
          
          <label class="md-nav__link" for="__nav_8" id="__nav_8_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    ‚ö° Optimize
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_8">
            <span class="md-nav__icon md-icon"></span>
            
  
    ‚ö° Optimize
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gepa-optimization/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üß¨ GEPA Optimizer
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../rlm-experimental/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üß™ RLM (Experimental)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../optimization/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üìà Optimization Guide
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../dspy-optimizers/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üî¨ DSPy Optimizers
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorials/openai-sdk-gepa-optimization/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üîß OpenAI SDK + GEPA Optimization
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorials/rag-optimization/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üîç RAG Optimization
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorials/mcp-optimization/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üîå MCP Optimization
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../memory-optimization/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üí° Memory Optimization
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_9" >
        
          
          <label class="md-nav__link" for="__nav_9" id="__nav_9_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    üéº Orchestrate
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_9">
            <span class="md-nav__icon md-icon"></span>
            
  
    üéº Orchestrate
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../orchestra-development/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üéº Orchestra Development
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorials/first-orchestra/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üéº Multi-Agent Orchestra
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_10" >
        
          
          <label class="md-nav__link" for="__nav_10" id="__nav_10_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    üìä Monitor
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_10_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_10">
            <span class="md-nav__icon md-icon"></span>
            
  
    üìä Monitor
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../observability/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üìä Observability Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mlflow-guide/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üßø MLFlow
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../langfuse-integration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üß¨ LangFuse
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../logfire-integration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üî• LogFire
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../weights-biases-integration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üìà Weights & Biases
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../observability-comparison/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ‚öñÔ∏è Comparison
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../enhanced-observability/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üöÄ Enhanced
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_11" >
        
          
          <label class="md-nav__link" for="__nav_11" id="__nav_11_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    üóÑÔ∏è Context
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_11_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_11">
            <span class="md-nav__icon md-icon"></span>
            
  
    üóÑÔ∏è Context
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mcp-rag-complete-guide/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üîç RAG & MCP Guide
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../rag/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üìö RAG Configuration
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../protocol-first-agents/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üîå MCP Protocol
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../dataset-import/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üìä Dataset Import
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../memory/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üß† Memory Systems
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_12" >
        
          
          <label class="md-nav__link" for="__nav_12" id="__nav_12_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    üîå Integrations
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_12_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_12">
            <span class="md-nav__icon md-icon"></span>
            
  
    üîå Integrations
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/agents/optimas-examples/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ‚ö° Optimas
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../optimas-integration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ‚ö° Optimas Guide
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stackone-integration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üóÇÔ∏è StackOne Integration
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stackone-claude-sdk/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üóÇÔ∏è StackOne + Claude SDK
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/agents/rag-chroma-demo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üö• ChromaDB
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/agents/rag-lancedb-demo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üçÄ LanceDB
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/agents/weaviate-demo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üî∞ Weaviate
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/agents/qdrant-demo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üî∏ Qdrant
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/agents/milvus-demo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üëÅÔ∏è Milvus
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/agents/tools-demo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üõ†Ô∏è Tools
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/agents/memory-demo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üß† Memory
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/agents/observability-demo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üìä Observability
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/agents/mlflow-integration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üßø MLFlow
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/agents/langfuse-integration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üß¨ LangFuse
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/agents/gepa-integration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üöÄ GEPA
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_13" >
        
          
          <label class="md-nav__link" for="__nav_13" id="__nav_13_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    üíª CLI
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_13_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_13">
            <span class="md-nav__icon md-icon"></span>
            
  
    üíª CLI
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cli-complete-guide/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üìò CLI Complete Guide
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/cli.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üìñ CLI Reference
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_14" >
        
          
          <label class="md-nav__link" for="__nav_14" id="__nav_14_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    ‚ú® Super CLI (Beta)
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_14_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_14">
            <span class="md-nav__icon md-icon"></span>
            
  
    ‚ú® Super CLI (Beta)
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../super-cli/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üí¨ Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../conversational-interface/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üîß Technical Details
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_15" checked>
        
          
          <label class="md-nav__link" for="__nav_15" id="__nav_15_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    ü§ñ Models
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_15_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_15">
            <span class="md-nav__icon md-icon"></span>
            
  
    ü§ñ Models
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    
  
    üß† Model Management
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    üß† Model Management
  

    
  </span>
  
  

      </a>
      
        

  

<nav class="md-nav md-nav--secondary" aria-label="On this page">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      On this page
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#quick-start" class="md-nav__link">
    <span class="md-ellipsis">
      
        Quick Start
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#installing-models" class="md-nav__link">
    <span class="md-ellipsis">
      
        Installing Models
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Installing Models">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#basic-installation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Basic Installation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#backend-specific-installation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Backend-Specific Installation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gpt-oss-openais-open-source" class="md-nav__link">
    <span class="md-ellipsis">
      
        GPT-OSS (OpenAI's Open Source)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mlx" class="md-nav__link">
    <span class="md-ellipsis">
      
        MLX
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#running-models" class="md-nav__link">
    <span class="md-ellipsis">
      
        Running Models
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Running Models">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#basic-usage" class="md-nav__link">
    <span class="md-ellipsis">
      
        Basic Usage
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#interactive-mode" class="md-nav__link">
    <span class="md-ellipsis">
      
        Interactive Mode
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#advanced-parameters" class="md-nav__link">
    <span class="md-ellipsis">
      
        Advanced Parameters
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#backend-specific-examples" class="md-nav__link">
    <span class="md-ellipsis">
      
        Backend-Specific Examples
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gpt-oss-models" class="md-nav__link">
    <span class="md-ellipsis">
      
        ü§ñ GPT-OSS Models
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ü§ñ GPT-OSS Models">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#gpt-oss-model-overview" class="md-nav__link">
    <span class="md-ellipsis">
      
        üéØ GPT-OSS Model Overview
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#key-features" class="md-nav__link">
    <span class="md-ellipsis">
      
        üöÄ Key Features
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#installing-gpt-oss-models" class="md-nav__link">
    <span class="md-ellipsis">
      
        üì¶ Installing GPT-OSS Models
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="üì¶ Installing GPT-OSS Models">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#via-mlx-lm-apple-silicon-native-support" class="md-nav__link">
    <span class="md-ellipsis">
      
        Via MLX-LM (Apple Silicon - Native Support)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#via-ollama-cross-platform-best-performance" class="md-nav__link">
    <span class="md-ellipsis">
      
        Via Ollama (Cross-Platform - Best Performance)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#via-huggingface-limited-on-apple-silicon" class="md-nav__link">
    <span class="md-ellipsis">
      
        Via HuggingFace (Limited on Apple Silicon)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#via-huggingface" class="md-nav__link">
    <span class="md-ellipsis">
      
        Via HuggingFace
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#using-gpt-oss-models" class="md-nav__link">
    <span class="md-ellipsis">
      
        üéØ Using GPT-OSS Models
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#basic-usage-examples" class="md-nav__link">
    <span class="md-ellipsis">
      
        üîß Basic Usage Examples
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#performance-recommendations" class="md-nav__link">
    <span class="md-ellipsis">
      
        üéØ Performance Recommendations
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#auto-installation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Auto-Installation
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#managing-models" class="md-nav__link">
    <span class="md-ellipsis">
      
        Managing Models
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Managing Models">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#listing-models" class="md-nav__link">
    <span class="md-ellipsis">
      
        Listing Models
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#removing-models" class="md-nav__link">
    <span class="md-ellipsis">
      
        Removing Models
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#getting-model-information" class="md-nav__link">
    <span class="md-ellipsis">
      
        Getting Model Information
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#refreshing-cache" class="md-nav__link">
    <span class="md-ellipsis">
      
        Refreshing Cache
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#backend-specific-features" class="md-nav__link">
    <span class="md-ellipsis">
      
        Backend-Specific Features
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Backend-Specific Features">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mlx-commands" class="md-nav__link">
    <span class="md-ellipsis">
      
        MLX Commands
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mlx-evaluation" class="md-nav__link">
    <span class="md-ellipsis">
      
        MLX Evaluation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mlx-fusion" class="md-nav__link">
    <span class="md-ellipsis">
      
        MLX Fusion
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mlx-finetuning" class="md-nav__link">
    <span class="md-ellipsis">
      
        MLX Finetuning
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#advanced-mlx-configuration" class="md-nav__link">
    <span class="md-ellipsis">
      
        Advanced MLX Configuration
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#training-data-format" class="md-nav__link">
    <span class="md-ellipsis">
      
        Training Data Format
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vllm-commands" class="md-nav__link">
    <span class="md-ellipsis">
      
        vLLM Commands
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vllm-setup-requirements" class="md-nav__link">
    <span class="md-ellipsis">
      
        vLLM Setup Requirements
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vllm-serving" class="md-nav__link">
    <span class="md-ellipsis">
      
        vLLM Serving
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vllm-generation" class="md-nav__link">
    <span class="md-ellipsis">
      
        vLLM Generation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vllm-benchmarking" class="md-nav__link">
    <span class="md-ellipsis">
      
        vLLM Benchmarking
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vllm-quantization" class="md-nav__link">
    <span class="md-ellipsis">
      
        vLLM Quantization
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vllm-troubleshooting" class="md-nav__link">
    <span class="md-ellipsis">
      
        vLLM Troubleshooting
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sglang-commands" class="md-nav__link">
    <span class="md-ellipsis">
      
        SGLang Commands
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sglang-setup-requirements" class="md-nav__link">
    <span class="md-ellipsis">
      
        SGLang Setup Requirements
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sglang-serving" class="md-nav__link">
    <span class="md-ellipsis">
      
        SGLang Serving
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sglang-generation" class="md-nav__link">
    <span class="md-ellipsis">
      
        SGLang Generation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sglang-optimization" class="md-nav__link">
    <span class="md-ellipsis">
      
        SGLang Optimization
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sglang-benchmarking" class="md-nav__link">
    <span class="md-ellipsis">
      
        SGLang Benchmarking
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sglang-troubleshooting" class="md-nav__link">
    <span class="md-ellipsis">
      
        SGLang Troubleshooting
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#server-management" class="md-nav__link">
    <span class="md-ellipsis">
      
        Server Management
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Server Management">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#starting-local-servers" class="md-nav__link">
    <span class="md-ellipsis">
      
        Starting Local Servers
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#using-servers-in-playbooks" class="md-nav__link">
    <span class="md-ellipsis">
      
        Using Servers in Playbooks
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model-conversion-and-quantization" class="md-nav__link">
    <span class="md-ellipsis">
      
        Model Conversion and Quantization
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#troubleshooting" class="md-nav__link">
    <span class="md-ellipsis">
      
        Troubleshooting
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Troubleshooting">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#common-issues" class="md-nav__link">
    <span class="md-ellipsis">
      
        Common Issues
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#auto-installation-workflow" class="md-nav__link">
    <span class="md-ellipsis">
      
        Auto-Installation Workflow
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#best-practices" class="md-nav__link">
    <span class="md-ellipsis">
      
        Best Practices
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Best Practices">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#model-selection" class="md-nav__link">
    <span class="md-ellipsis">
      
        Model Selection
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#resources" class="md-nav__link">
    <span class="md-ellipsis">
      
        Resources
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#next-steps" class="md-nav__link">
    <span class="md-ellipsis">
      
        Next Steps
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Next Steps">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#backend-selection" class="md-nav__link">
    <span class="md-ellipsis">
      
        Backend Selection
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#performance-optimization" class="md-nav__link">
    <span class="md-ellipsis">
      
        Performance Optimization
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#examples" class="md-nav__link">
    <span class="md-ellipsis">
      
        Examples
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Examples">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#complete-workflow" class="md-nav__link">
    <span class="md-ellipsis">
      
        Complete Workflow
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#testing-mlx-features" class="md-nav__link">
    <span class="md-ellipsis">
      
        Testing MLX Features
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#dependency-overview" class="md-nav__link">
    <span class="md-ellipsis">
      
        Dependency Overview
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Dependency Overview">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#core-dependencies-always-included" class="md-nav__link">
    <span class="md-ellipsis">
      
        Core Dependencies (Always Included)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#optional-dependencies-install-as-needed" class="md-nav__link">
    <span class="md-ellipsis">
      
        Optional Dependencies (Install as needed)
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../model-intelligence/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üí° Model Intelligence
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_15_3" >
        
          
          <label class="md-nav__link" for="__nav_15_3" id="__nav_15_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    üíª Local Inference
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_15_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_15_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    üíª Local Inference
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/agents/mlx-demo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üíª MLX (Apple Silicon)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/agents/ollama-demo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üêº Ollama
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/agents/huggingface-demo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ü§ó HuggingFace
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/agents/lmstudio-demo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üéõÔ∏è LM Studio
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_15_4" >
        
          
          <label class="md-nav__link" for="__nav_15_4" id="__nav_15_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    ‚òÅÔ∏è Cloud
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_15_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_15_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    ‚òÅÔ∏è Cloud
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cloud-inference/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ‚òÅÔ∏è Cloud Inference (OpenAI, Anthropic, Google)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../vllm-inference/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üöÄ vLLM (High-Performance Serving)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../sglang-inference/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ‚ö° SGLang (Structured Generation)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_16" >
        
          
          <label class="md-nav__link" for="__nav_16" id="__nav_16_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    üìö Examples
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_16_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_16">
            <span class="md-nav__icon md-icon"></span>
            
  
    üìö Examples
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üìö Examples Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/agents/optimas-examples/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ‚ö° Optimas
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/agents/rag-chroma-demo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üö• ChromaDB
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/agents/rag-lancedb-demo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üçÄ LanceDB
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/agents/weaviate-demo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üî∞ Weaviate
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/agents/qdrant-demo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üî∏ Qdrant
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/agents/milvus-demo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üëÅÔ∏è Milvus
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/agents/tools-demo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üõ†Ô∏è Tools
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/agents/memory-demo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üß† Memory
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/agents/observability-demo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üìä Observability
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/agents/mlflow-integration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üßø MLFlow
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/agents/langfuse-integration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üß¨ LangFuse
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/agents/weights-biases-demo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üìà Weights & Biases
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/agents/gepa-integration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üöÄ GEPA
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_17" >
        
          
          <label class="md-nav__link" for="__nav_17" id="__nav_17_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    üéØ Techniques
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_17_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_17">
            <span class="md-nav__icon md-icon"></span>
            
  
    üéØ Techniques
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../techniques/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üéØ Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../memory/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üß† Memory Systems
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../memory-optimization/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üí° Memory Optimization
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../rag/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üìö RAG Configuration
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../optimization/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üìà Optimization Guide
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../evaluation-testing/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Evaluation & Testing
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../observability/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üìä Observability Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bdd/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üé≠ RSpec-Style BDD Testing
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cicd-integration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üîÑ CI/CD Integration
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../rails-analogy/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üöÇ Rails Analogy (For Rails Devs)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_18" >
        
          
          <label class="md-nav__link" for="__nav_18" id="__nav_18_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    üõçÔ∏è Marketplace
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_18_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_18">
            <span class="md-nav__icon md-icon"></span>
            
  
    üõçÔ∏è Marketplace
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../marketplace/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üõçÔ∏è Marketplace Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_19" >
        
          
          <label class="md-nav__link" for="__nav_19" id="__nav_19_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Responsible AI
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_19_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_19">
            <span class="md-nav__icon md-icon"></span>
            
  
    Responsible AI
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../responsible-ai/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Responsible AI Guide
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_20" >
        
          
          <label class="md-nav__link" for="__nav_20" id="__nav_20_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    üè¢ Company
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_20_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_20">
            <span class="md-nav__icon md-icon"></span>
            
  
    üè¢ Company
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../superagentic-ai/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üåü Superagentic AI
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_21" >
        
          
          <label class="md-nav__link" for="__nav_21" id="__nav_21_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    üìñ Reference
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_21_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_21">
            <span class="md-nav__icon md-icon"></span>
            
  
    üìñ Reference
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/index.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üìö Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_21_2" >
        
          
          <label class="md-nav__link" for="__nav_21_2" id="__nav_21_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    üîß API Reference
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_21_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_21_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    üîß API Reference
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/api/index.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    API Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/api/superspec.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üìù SuperSpec API
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/api/gepa.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üß¨ GEPA API
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/api/dspy-optimizers.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üî¨ DSPy Optimizers API
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/api/runners.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üèÉ Runners API
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/api/memory.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üß† Memory API
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/api/models.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ü§ñ Models API
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/api/tools.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üîß Tools API
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/api/observability.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üìä Observability API
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/api/cli.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üíª CLI API
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/api/core.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üîß Core API
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../faq/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ‚ùì FAQ
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../debugging-guide/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    üêõ Debugging
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

  

<nav class="md-nav md-nav--secondary" aria-label="On this page">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      On this page
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#quick-start" class="md-nav__link">
    <span class="md-ellipsis">
      
        Quick Start
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#installing-models" class="md-nav__link">
    <span class="md-ellipsis">
      
        Installing Models
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Installing Models">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#basic-installation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Basic Installation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#backend-specific-installation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Backend-Specific Installation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gpt-oss-openais-open-source" class="md-nav__link">
    <span class="md-ellipsis">
      
        GPT-OSS (OpenAI's Open Source)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mlx" class="md-nav__link">
    <span class="md-ellipsis">
      
        MLX
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#running-models" class="md-nav__link">
    <span class="md-ellipsis">
      
        Running Models
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Running Models">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#basic-usage" class="md-nav__link">
    <span class="md-ellipsis">
      
        Basic Usage
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#interactive-mode" class="md-nav__link">
    <span class="md-ellipsis">
      
        Interactive Mode
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#advanced-parameters" class="md-nav__link">
    <span class="md-ellipsis">
      
        Advanced Parameters
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#backend-specific-examples" class="md-nav__link">
    <span class="md-ellipsis">
      
        Backend-Specific Examples
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gpt-oss-models" class="md-nav__link">
    <span class="md-ellipsis">
      
        ü§ñ GPT-OSS Models
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ü§ñ GPT-OSS Models">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#gpt-oss-model-overview" class="md-nav__link">
    <span class="md-ellipsis">
      
        üéØ GPT-OSS Model Overview
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#key-features" class="md-nav__link">
    <span class="md-ellipsis">
      
        üöÄ Key Features
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#installing-gpt-oss-models" class="md-nav__link">
    <span class="md-ellipsis">
      
        üì¶ Installing GPT-OSS Models
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="üì¶ Installing GPT-OSS Models">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#via-mlx-lm-apple-silicon-native-support" class="md-nav__link">
    <span class="md-ellipsis">
      
        Via MLX-LM (Apple Silicon - Native Support)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#via-ollama-cross-platform-best-performance" class="md-nav__link">
    <span class="md-ellipsis">
      
        Via Ollama (Cross-Platform - Best Performance)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#via-huggingface-limited-on-apple-silicon" class="md-nav__link">
    <span class="md-ellipsis">
      
        Via HuggingFace (Limited on Apple Silicon)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#via-huggingface" class="md-nav__link">
    <span class="md-ellipsis">
      
        Via HuggingFace
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#using-gpt-oss-models" class="md-nav__link">
    <span class="md-ellipsis">
      
        üéØ Using GPT-OSS Models
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#basic-usage-examples" class="md-nav__link">
    <span class="md-ellipsis">
      
        üîß Basic Usage Examples
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#performance-recommendations" class="md-nav__link">
    <span class="md-ellipsis">
      
        üéØ Performance Recommendations
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#auto-installation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Auto-Installation
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#managing-models" class="md-nav__link">
    <span class="md-ellipsis">
      
        Managing Models
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Managing Models">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#listing-models" class="md-nav__link">
    <span class="md-ellipsis">
      
        Listing Models
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#removing-models" class="md-nav__link">
    <span class="md-ellipsis">
      
        Removing Models
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#getting-model-information" class="md-nav__link">
    <span class="md-ellipsis">
      
        Getting Model Information
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#refreshing-cache" class="md-nav__link">
    <span class="md-ellipsis">
      
        Refreshing Cache
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#backend-specific-features" class="md-nav__link">
    <span class="md-ellipsis">
      
        Backend-Specific Features
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Backend-Specific Features">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mlx-commands" class="md-nav__link">
    <span class="md-ellipsis">
      
        MLX Commands
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mlx-evaluation" class="md-nav__link">
    <span class="md-ellipsis">
      
        MLX Evaluation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mlx-fusion" class="md-nav__link">
    <span class="md-ellipsis">
      
        MLX Fusion
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mlx-finetuning" class="md-nav__link">
    <span class="md-ellipsis">
      
        MLX Finetuning
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#advanced-mlx-configuration" class="md-nav__link">
    <span class="md-ellipsis">
      
        Advanced MLX Configuration
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#training-data-format" class="md-nav__link">
    <span class="md-ellipsis">
      
        Training Data Format
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vllm-commands" class="md-nav__link">
    <span class="md-ellipsis">
      
        vLLM Commands
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vllm-setup-requirements" class="md-nav__link">
    <span class="md-ellipsis">
      
        vLLM Setup Requirements
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vllm-serving" class="md-nav__link">
    <span class="md-ellipsis">
      
        vLLM Serving
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vllm-generation" class="md-nav__link">
    <span class="md-ellipsis">
      
        vLLM Generation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vllm-benchmarking" class="md-nav__link">
    <span class="md-ellipsis">
      
        vLLM Benchmarking
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vllm-quantization" class="md-nav__link">
    <span class="md-ellipsis">
      
        vLLM Quantization
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vllm-troubleshooting" class="md-nav__link">
    <span class="md-ellipsis">
      
        vLLM Troubleshooting
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sglang-commands" class="md-nav__link">
    <span class="md-ellipsis">
      
        SGLang Commands
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sglang-setup-requirements" class="md-nav__link">
    <span class="md-ellipsis">
      
        SGLang Setup Requirements
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sglang-serving" class="md-nav__link">
    <span class="md-ellipsis">
      
        SGLang Serving
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sglang-generation" class="md-nav__link">
    <span class="md-ellipsis">
      
        SGLang Generation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sglang-optimization" class="md-nav__link">
    <span class="md-ellipsis">
      
        SGLang Optimization
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sglang-benchmarking" class="md-nav__link">
    <span class="md-ellipsis">
      
        SGLang Benchmarking
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sglang-troubleshooting" class="md-nav__link">
    <span class="md-ellipsis">
      
        SGLang Troubleshooting
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#server-management" class="md-nav__link">
    <span class="md-ellipsis">
      
        Server Management
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Server Management">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#starting-local-servers" class="md-nav__link">
    <span class="md-ellipsis">
      
        Starting Local Servers
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#using-servers-in-playbooks" class="md-nav__link">
    <span class="md-ellipsis">
      
        Using Servers in Playbooks
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model-conversion-and-quantization" class="md-nav__link">
    <span class="md-ellipsis">
      
        Model Conversion and Quantization
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#troubleshooting" class="md-nav__link">
    <span class="md-ellipsis">
      
        Troubleshooting
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Troubleshooting">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#common-issues" class="md-nav__link">
    <span class="md-ellipsis">
      
        Common Issues
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#auto-installation-workflow" class="md-nav__link">
    <span class="md-ellipsis">
      
        Auto-Installation Workflow
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#best-practices" class="md-nav__link">
    <span class="md-ellipsis">
      
        Best Practices
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Best Practices">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#model-selection" class="md-nav__link">
    <span class="md-ellipsis">
      
        Model Selection
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#resources" class="md-nav__link">
    <span class="md-ellipsis">
      
        Resources
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#next-steps" class="md-nav__link">
    <span class="md-ellipsis">
      
        Next Steps
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Next Steps">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#backend-selection" class="md-nav__link">
    <span class="md-ellipsis">
      
        Backend Selection
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#performance-optimization" class="md-nav__link">
    <span class="md-ellipsis">
      
        Performance Optimization
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#examples" class="md-nav__link">
    <span class="md-ellipsis">
      
        Examples
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Examples">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#complete-workflow" class="md-nav__link">
    <span class="md-ellipsis">
      
        Complete Workflow
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#testing-mlx-features" class="md-nav__link">
    <span class="md-ellipsis">
      
        Testing MLX Features
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#dependency-overview" class="md-nav__link">
    <span class="md-ellipsis">
      
        Dependency Overview
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Dependency Overview">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#core-dependencies-always-included" class="md-nav__link">
    <span class="md-ellipsis">
      
        Core Dependencies (Always Included)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#optional-dependencies-install-as-needed" class="md-nav__link">
    <span class="md-ellipsis">
      
        Optional Dependencies (Install as needed)
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
                



  


  <nav class="md-path" aria-label="Navigation" >
    <ol class="md-path__list">
      
        
  
  
    <li class="md-path__item">
      <a href="../.." class="md-path__link">
        
  <span class="md-ellipsis">
    üè† Home
  </span>

      </a>
    </li>
  

      
      
        
  
  
    
    
      <li class="md-path__item">
        <a href="./" class="md-path__link">
          
  <span class="md-ellipsis">
    ü§ñ Models
  </span>

        </a>
      </li>
    
  

      
    </ol>
  </nav>

              
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="model-management-guide">Model Management Guide</h1>
<p>SuperOptiX provides a unified model management system that supports multiple backends including Ollama, MLX, HuggingFace, LM Studio, vLLM, and SGLang. This guide covers how to install, manage, and use models across different backends.</p>
<h2 id="quick-start">Quick Start</h2>
<p>The easiest way to use models is with the <code>super model run</code> command:</p>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Run a model with auto-installation</span>
super<span class="w"> </span>model<span class="w"> </span>run<span class="w"> </span>llama3.2:3b<span class="w"> </span><span class="s2">&quot;Write a Python function to add two numbers&quot;</span>

<span class="c1"># Specify backend explicitly</span>
super<span class="w"> </span>model<span class="w"> </span>run<span class="w"> </span>llama3.2:3b<span class="w"> </span><span class="s2">&quot;Write a hello world program&quot;</span><span class="w"> </span>--backend<span class="w"> </span>ollama

<span class="c1"># Interactive mode</span>
super<span class="w"> </span>model<span class="w"> </span>run<span class="w"> </span>llama3.2:3b<span class="w"> </span><span class="s2">&quot;&quot;</span><span class="w"> </span>--interactive
</code></pre></div>
<h2 id="installing-models">Installing Models</h2>
<h3 id="basic-installation">Basic Installation</h3>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Install Ollama model (default backend)</span>
super<span class="w"> </span>model<span class="w"> </span>install<span class="w"> </span>llama3.2:3b<span class="w"> </span>--backend<span class="w"> </span>ollama

<span class="c1"># Install MLX model</span>
super<span class="w"> </span>model<span class="w"> </span>install<span class="w"> </span>mlx-community/Llama-3.2-3B-Instruct-4bit<span class="w"> </span>--backend<span class="w"> </span>mlx

<span class="c1"># Install HuggingFace model</span>
super<span class="w"> </span>model<span class="w"> </span>install<span class="w"> </span>microsoft/phi-1_5<span class="w"> </span>--backend<span class="w"> </span>huggingface
</code></pre></div>
<h3 id="backend-specific-installation">Backend-Specific Installation</h3>
<p>Each backend has different installation methods:</p>
<ul>
<li><strong>Ollama</strong>: Uses <code>ollama pull</code> internally</li>
<li><strong>MLX</strong>: Downloads from HuggingFace Hub and converts to MLX format</li>
<li><strong>HuggingFace</strong>: Downloads using transformers library</li>
<li><strong>LM Studio</strong>: Manual installation via desktop app</li>
</ul>
<h3 id="gpt-oss-openais-open-source">GPT-OSS (OpenAI's Open Source)</h3>
<ul>
<li><strong>Best for:</strong> Advanced reasoning, complex tasks</li>
<li><strong>Models:</strong> GPT-OSS-20B, GPT-OSS-120B</li>
<li><strong>Installation:</strong> </li>
<li><code>super model install gpt-oss:20b</code> (Ollama - best performance)</li>
<li><code>super model install lmstudio-community/gpt-oss-20b-MLX-8bit --backend mlx</code> (Apple Silicon - native support)</li>
<li><code>super model install openai/gpt-oss-20b --backend huggingface</code> (Limited on Apple Silicon)</li>
<li><strong>Execution:</strong> Direct inference</li>
<li><strong>Features:</strong> Apache 2.0 license, MXFP4 quantization, Apple Silicon native support</li>
<li><strong>Resources:</strong> <a href="https://huggingface.co/openai/gpt-oss-120b">GPT-OSS-120B</a>, <a href="https://huggingface.co/openai/gpt-oss-20b">GPT-OSS-20B</a>, <a href="https://ollama.com/library/gpt-oss">Ollama Library</a></li>
</ul>
<h3 id="mlx">MLX</h3>
<ul>
<li><strong>Best for:</strong> Apple Silicon optimization, GPT-OSS native support</li>
<li><strong>Models:</strong> MLX-community models, GPT-OSS models</li>
<li><strong>Installation:</strong> Downloads from HuggingFace Hub</li>
<li><strong>Execution:</strong> Direct MLX-LM inference</li>
<li><strong>Features:</strong> Native Apple Silicon support for GPT-OSS models</li>
</ul>
<h2 id="running-models">Running Models</h2>
<h3 id="basic-usage">Basic Usage</h3>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Run with auto-detection</span>
super<span class="w"> </span>model<span class="w"> </span>run<span class="w"> </span>&lt;model_name&gt;<span class="w"> </span><span class="s2">&quot;&lt;prompt&gt;&quot;</span>

<span class="c1"># Examples</span>
super<span class="w"> </span>model<span class="w"> </span>run<span class="w"> </span>llama3.2:3b<span class="w"> </span><span class="s2">&quot;Write a Python function to calculate fibonacci&quot;</span>
super<span class="w"> </span>model<span class="w"> </span>run<span class="w"> </span>mlx-community/phi-2<span class="w"> </span><span class="s2">&quot;Explain quantum computing in simple terms&quot;</span>
super<span class="w"> </span>model<span class="w"> </span>run<span class="w"> </span>microsoft/phi-1_5<span class="w"> </span><span class="s2">&quot;Write a simple calculator program&quot;</span>
</code></pre></div>
<h3 id="interactive-mode">Interactive Mode</h3>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Start interactive session</span>
super<span class="w"> </span>model<span class="w"> </span>run<span class="w"> </span>&lt;model_name&gt;<span class="w"> </span><span class="s2">&quot;&quot;</span><span class="w"> </span>--interactive

<span class="c1"># Example</span>
super<span class="w"> </span>model<span class="w"> </span>run<span class="w"> </span>llama3.2:3b<span class="w"> </span><span class="s2">&quot;Write a story&quot;</span><span class="w"> </span>--interactive
</code></pre></div>
<h3 id="advanced-parameters">Advanced Parameters</h3>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Control generation parameters</span>
super<span class="w"> </span>model<span class="w"> </span>run<span class="w"> </span>llama3.2:3b<span class="w"> </span><span class="s2">&quot;Write a story&quot;</span><span class="w"> </span>--temperature<span class="w"> </span><span class="m">0</span>.9
super<span class="w"> </span>model<span class="w"> </span>run<span class="w"> </span>llama3.2:3b<span class="w"> </span><span class="s2">&quot;Explain AI&quot;</span><span class="w"> </span>--max-tokens<span class="w"> </span><span class="m">500</span>
super<span class="w"> </span>model<span class="w"> </span>run<span class="w"> </span>llama3.2:3b<span class="w"> </span><span class="s2">&quot;Write a poem&quot;</span><span class="w"> </span>--temperature<span class="w"> </span><span class="m">0</span>.8<span class="w"> </span>--max-tokens<span class="w"> </span><span class="m">200</span>
</code></pre></div>
<h3 id="backend-specific-examples">Backend-Specific Examples</h3>
<h2 id="gpt-oss-models">ü§ñ GPT-OSS Models</h2>
<p>SuperOptiX now supports OpenAI's latest open-source language models: <strong>GPT-OSS-20B</strong> and <strong>GPT-OSS-120B</strong>. These models are designed for advanced reasoning and agentic tasks.</p>
<h3 id="gpt-oss-model-overview">üéØ GPT-OSS Model Overview</h3>
<table>
<thead>
<tr>
<th>Model</th>
<th>Parameters</th>
<th>Active Parameters</th>
<th>Best For</th>
<th>Hardware Requirements</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>GPT-OSS-20B</strong></td>
<td>21B</td>
<td>3.6B</td>
<td>Lower latency, local/specialized use cases</td>
<td>16GB+ RAM</td>
</tr>
<tr>
<td><strong>GPT-OSS-120B</strong></td>
<td>117B</td>
<td>5.1B</td>
<td>Production, general purpose, high reasoning</td>
<td>Single H100 GPU</td>
</tr>
</tbody>
</table>
<h3 id="key-features">üöÄ Key Features</h3>
<ul>
<li><strong>üîì Apache 2.0 License</strong>: Build freely without copyleft restrictions</li>
<li><strong>‚ö° Native MXFP4 Quantization</strong>: Optimized for efficient inference</li>
</ul>
<h3 id="installing-gpt-oss-models">üì¶ Installing GPT-OSS Models</h3>
<h4 id="via-mlx-lm-apple-silicon-native-support">Via MLX-LM (Apple Silicon - Native Support)</h4>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Install GPT-OSS models via MLX-LM (Apple Silicon only)</span>
super<span class="w"> </span>model<span class="w"> </span>install<span class="w"> </span>openai_gpt-oss-20b<span class="w"> </span>--backend<span class="w"> </span>mlx
super<span class="w"> </span>model<span class="w"> </span>install<span class="w"> </span>lmstudio-community/gpt-oss-120b-MLX-8bit<span class="w"> </span>--backend<span class="w"> </span>mlx

<span class="c1"># Test the models</span>
super<span class="w"> </span>model<span class="w"> </span>run<span class="w"> </span>lmstudio-community/gpt-oss-20b-MLX-8bit<span class="w"> </span><span class="s2">&quot;Explain quantum computing with detailed reasoning&quot;</span><span class="w"> </span>--backend<span class="w"> </span>mlx
</code></pre></div>
<h4 id="via-ollama-cross-platform-best-performance">Via Ollama (Cross-Platform - Best Performance)</h4>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Install GPT-OSS models</span>
super<span class="w"> </span>model<span class="w"> </span>install<span class="w"> </span>gpt-oss:20b
super<span class="w"> </span>model<span class="w"> </span>install<span class="w"> </span>gpt-oss:120b

<span class="c1"># Test the models</span>
super<span class="w"> </span>model<span class="w"> </span>run<span class="w"> </span>gpt-oss:20b<span class="w"> </span><span class="s2">&quot;Explain quantum computing with detailed reasoning&quot;</span><span class="w"> </span>--backend<span class="w"> </span>ollama
</code></pre></div>
<h4 id="via-huggingface-limited-on-apple-silicon">Via HuggingFace (Limited on Apple Silicon)</h4>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Install GPT-OSS models via MLX (Apple Silicon - Recommended)</span>
super<span class="w"> </span>model<span class="w"> </span>install<span class="w"> </span>lmstudio-community/gpt-oss-20b-MLX-8bit<span class="w"> </span>--backend<span class="w"> </span>mlx
super<span class="w"> </span>model<span class="w"> </span>install<span class="w"> </span>lmstudio-community/gpt-oss-120b-MLX-8bit<span class="w"> </span>--backend<span class="w"> </span>mlx

<span class="c1"># Test the models</span>
super<span class="w"> </span>model<span class="w"> </span>run<span class="w"> </span>lmstudio-community/gpt-oss-20b-MLX-8bit<span class="w"> </span><span class="s2">&quot;Explain quantum computing with detailed reasoning&quot;</span><span class="w"> </span>--backend<span class="w"> </span>mlx
</code></pre></div>
<h4 id="via-huggingface">Via HuggingFace</h4>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Install via MLX (Apple Silicon - Recommended)</span>
super<span class="w"> </span>model<span class="w"> </span>install<span class="w"> </span>lmstudio-community/gpt-oss-20b-MLX-8bit<span class="w"> </span>--backend<span class="w"> </span>mlx
super<span class="w"> </span>model<span class="w"> </span>install<span class="w"> </span>lmstudio-community/gpt-oss-120b-MLX-8bit<span class="w"> </span>--backend<span class="w"> </span>mlx

<span class="c1"># Start server</span>
super<span class="w"> </span>model<span class="w"> </span>server<span class="w"> </span>mlx<span class="w"> </span>lmstudio-community/gpt-oss-20b-MLX-8bit<span class="w"> </span>--port<span class="w"> </span><span class="m">8000</span>
</code></pre></div>
<h3 id="using-gpt-oss-models">üéØ Using GPT-OSS Models</h3>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Simple question</span>
super<span class="w"> </span>model<span class="w"> </span>run<span class="w"> </span>gpt-oss:20b<span class="w"> </span><span class="s2">&quot;What is 2+2?&quot;</span>

<span class="c1"># Explain a concept</span>
super<span class="w"> </span>model<span class="w"> </span>run<span class="w"> </span>gpt-oss:20b<span class="w"> </span><span class="s2">&quot;Explain machine learning&quot;</span>

<span class="c1"># Complex task</span>
super<span class="w"> </span>model<span class="w"> </span>run<span class="w"> </span>gpt-oss:20b<span class="w"> </span><span class="s2">&quot;Design a distributed system architecture&quot;</span>
</code></pre></div>
<h3 id="basic-usage-examples">üîß Basic Usage Examples</h3>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Simple calculation</span>
super<span class="w"> </span>model<span class="w"> </span>run<span class="w"> </span>gpt-oss:20b<span class="w"> </span><span class="s2">&quot;Calculate the factorial of 10&quot;</span>

<span class="c1"># Get information</span>
super<span class="w"> </span>model<span class="w"> </span>run<span class="w"> </span>gpt-oss:20b<span class="w"> </span><span class="s2">&quot;What&#39;s the latest news about AI?&quot;</span>

<span class="c1"># Complex problem solving</span>
super<span class="w"> </span>model<span class="w"> </span>run<span class="w"> </span>gpt-oss:120b<span class="w"> </span><span class="s2">&quot;Solve: A train leaves station A at 2 PM traveling at 60 mph. Another train leaves station B at 3 PM traveling at 80 mph. When will they meet if the stations are 300 miles apart?&quot;</span>
</code></pre></div>
<h3 id="performance-recommendations">üéØ Performance Recommendations</h3>
<table>
<thead>
<tr>
<th>Use Case</th>
<th>Recommended Model</th>
<th>Hardware</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Quick responses</strong></td>
<td>GPT-OSS-20B</td>
<td>16GB+ RAM</td>
</tr>
<tr>
<td><strong>Complex tasks</strong></td>
<td>GPT-OSS-120B</td>
<td>H100 GPU</td>
</tr>
<tr>
<td><strong>Local development</strong></td>
<td>GPT-OSS-20B</td>
<td>16GB+ RAM</td>
</tr>
</tbody>
</table>
<h2 id="auto-installation">Auto-Installation</h2>
<p>Models are automatically installed when they're not found:</p>
<blockquote>
<blockquote>
<blockquote>
<blockquote>
<blockquote>
<blockquote>
<blockquote>
<p>open</p>
</blockquote>
</blockquote>
</blockquote>
</blockquote>
</blockquote>
</blockquote>
</blockquote>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Ollama models</span>
super<span class="w"> </span>model<span class="w"> </span>run<span class="w"> </span>llama3.2:3b<span class="w"> </span><span class="s2">&quot;Hello world&quot;</span>

<span class="c1"># MLX models</span>
super<span class="w"> </span>model<span class="w"> </span>run<span class="w"> </span>mlx-community/Llama-3.2-3B-Instruct-4bit<span class="w"> </span><span class="s2">&quot;Hello world&quot;</span>

<span class="c1"># HuggingFace models</span>
super<span class="w"> </span>model<span class="w"> </span>run<span class="w"> </span>microsoft/phi-1_5<span class="w"> </span><span class="s2">&quot;Hello world&quot;</span>
</code></pre></div>
<h2 id="managing-models">Managing Models</h2>
<h3 id="listing-models">Listing Models</h3>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># List all installed models</span>
super<span class="w"> </span>model<span class="w"> </span>list

<span class="c1"># List by backend</span>
super<span class="w"> </span>model<span class="w"> </span>list<span class="w"> </span>--backend<span class="w"> </span>ollama
super<span class="w"> </span>model<span class="w"> </span>list<span class="w"> </span>--backend<span class="w"> </span>mlx
super<span class="w"> </span>model<span class="w"> </span>list<span class="w"> </span>--backend<span class="w"> </span>huggingface

<span class="c1"># Filter by size</span>
super<span class="w"> </span>model<span class="w"> </span>list<span class="w"> </span>--size<span class="w"> </span>small

<span class="c1"># Filter by task</span>
super<span class="w"> </span>model<span class="w"> </span>list<span class="w"> </span>--task<span class="w"> </span>code
</code></pre></div>
<h3 id="removing-models">Removing Models</h3>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Remove from specific backend</span>
super<span class="w"> </span>model<span class="w"> </span>remove<span class="w"> </span>llama3.2:3b<span class="w"> </span>--backend<span class="w"> </span>ollama

<span class="c1"># Remove from all backends</span>
super<span class="w"> </span>model<span class="w"> </span>remove<span class="w"> </span>llama3.2:3b<span class="w"> </span>--all-backends

<span class="c1"># Auto-detect backend</span>
super<span class="w"> </span>model<span class="w"> </span>remove<span class="w"> </span>llama3.2:3b
</code></pre></div>
<h3 id="getting-model-information">Getting Model Information</h3>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Get detailed model info</span>
super<span class="w"> </span>model<span class="w"> </span>info<span class="w"> </span>llama3.2:3b

<span class="c1"># Get info for specific backend</span>
super<span class="w"> </span>model<span class="w"> </span>info<span class="w"> </span>microsoft/phi-1_5<span class="w"> </span>--backend<span class="w"> </span>huggingface
</code></pre></div>
<h3 id="refreshing-cache">Refreshing Cache</h3>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Refresh model cache</span>
super<span class="w"> </span>model<span class="w"> </span>refresh
</code></pre></div>
<h2 id="backend-specific-features">Backend-Specific Features</h2>
<h3 id="mlx-commands">MLX Commands</h3>
<p>MLX provides advanced features for Apple Silicon optimization:</p>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Convert HuggingFace models to MLX</span>
super<span class="w"> </span>model<span class="w"> </span>mlx<span class="w"> </span>convert<span class="w"> </span>microsoft/phi-2<span class="w"> </span>--output<span class="w"> </span>phi-2-mlx

<span class="c1"># Quantize MLX models</span>
super<span class="w"> </span>model<span class="w"> </span>mlx<span class="w"> </span>quantize<span class="w"> </span>phi-2-mlx<span class="w"> </span>--bits<span class="w"> </span><span class="m">4</span><span class="w"> </span>--group-size<span class="w"> </span><span class="m">64</span>

<span class="c1"># Finetune MLX models</span>
super<span class="w"> </span>model<span class="w"> </span>mlx<span class="w"> </span>finetune<span class="w"> </span>phi-2-mlx<span class="w"> </span>training_data<span class="w"> </span>--type<span class="w"> </span>lora<span class="w"> </span>--iters<span class="w"> </span><span class="m">1000</span>

<span class="c1"># Evaluate MLX models</span>
super<span class="w"> </span>model<span class="w"> </span>mlx<span class="w"> </span>evaluate<span class="w"> </span>phi-2-mlx<span class="w"> </span>--tasks<span class="w"> </span>mmlu,arc,hellaswag

<span class="c1"># Fuse adapters into base model</span>
super<span class="w"> </span>model<span class="w"> </span>mlx<span class="w"> </span>fuse<span class="w"> </span>phi-2-mlx<span class="w"> </span>--adapter-path<span class="w"> </span>adapters<span class="w"> </span>--save-path<span class="w"> </span>fused_model
</code></pre></div>
<h3 id="mlx-evaluation">MLX Evaluation</h3>
<p>Evaluate MLX models on standardized benchmarks using LM-Eval integration:</p>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Basic evaluation</span>
super<span class="w"> </span>model<span class="w"> </span>mlx<span class="w"> </span>evaluate<span class="w"> </span>phi-2-mlx<span class="w"> </span>--tasks<span class="w"> </span>mmlu,arc,hellaswag

<span class="c1"># Advanced evaluation with custom parameters</span>
super<span class="w"> </span>model<span class="w"> </span>mlx<span class="w"> </span>evaluate<span class="w"> </span>phi-2-mlx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tasks<span class="w"> </span>mmlu,arc,hellaswag<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--output-dir<span class="w"> </span>results<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--batch-size<span class="w"> </span><span class="m">32</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--shots<span class="w"> </span><span class="m">5</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--limit<span class="w"> </span><span class="m">100</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--seed<span class="w"> </span><span class="m">42</span>

<span class="c1"># Evaluation with chat template</span>
super<span class="w"> </span>model<span class="w"> </span>mlx<span class="w"> </span>evaluate<span class="w"> </span>phi-2-mlx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tasks<span class="w"> </span>mmlu<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--chat-template<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--max-tokens<span class="w"> </span><span class="m">2048</span>
</code></pre></div>
<p><strong>Setup Requirements:</strong>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Install evaluation dependencies</span>
pip<span class="w"> </span>install<span class="w"> </span>lm_eval

<span class="c1"># Verify MLX-LM installation</span>
python<span class="w"> </span>-c<span class="w"> </span><span class="s2">&quot;import mlx_lm; print(&#39;MLX-LM ready&#39;)&quot;</span>
</code></pre></div></p>
<p><strong>Dependencies:</strong>
- <code>lm_eval</code> - Required for evaluation (install with: <code>pip install lm_eval</code>)
- <code>mlx_lm</code> - Required for MLX operations</p>
<p><strong>Supported Tasks:</strong>
- <code>mmlu</code> - Massive Multitask Language Understanding
- <code>arc</code> - AI2 Reasoning Challenge
- <code>hellaswag</code> - HellaSwag
- <code>winogrande</code> - Winogrande
- <code>truthfulqa</code> - TruthfulQA
- <code>gsm8k</code> - Grade School Math 8K</p>
<p><strong>Evaluation Parameters:</strong>
- <code>--tasks</code>: Comma-separated list of evaluation tasks
- <code>--output-dir</code>: Directory to save results
- <code>--batch-size</code>: Batch size for evaluation (default: 16)
- <code>--shots</code>: Number of few-shot examples
- <code>--limit</code>: Limit examples per task
- <code>--seed</code>: Random seed for reproducibility
- <code>--max-tokens</code>: Maximum tokens for generation
- <code>--chat-template</code>: Use chat template for evaluation</p>
<h3 id="mlx-fusion">MLX Fusion</h3>
<p>Fuse finetuned adapters (LoRA/DoRA) into base models for deployment:</p>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Basic fusion</span>
super<span class="w"> </span>model<span class="w"> </span>mlx<span class="w"> </span>fuse<span class="w"> </span>phi-2-mlx<span class="w"> </span>--adapter-path<span class="w"> </span>adapters

<span class="c1"># Fusion with dequantization</span>
super<span class="w"> </span>model<span class="w"> </span>mlx<span class="w"> </span>fuse<span class="w"> </span>phi-2-mlx<span class="w"> </span>--adapter-path<span class="w"> </span>adapters<span class="w"> </span>--dequantize

<span class="c1"># Fusion with GGUF export</span>
super<span class="w"> </span>model<span class="w"> </span>mlx<span class="w"> </span>fuse<span class="w"> </span>phi-2-mlx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--adapter-path<span class="w"> </span>adapters<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--export-gguf<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--gguf-path<span class="w"> </span>phi-2-fused.gguf

<span class="c1"># Fusion with HuggingFace upload</span>
super<span class="w"> </span>model<span class="w"> </span>mlx<span class="w"> </span>fuse<span class="w"> </span>phi-2-mlx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--adapter-path<span class="w"> </span>adapters<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--upload<span class="w"> </span>username/phi-2-fused
</code></pre></div>
<p><strong>Fusion Parameters:</strong>
- <code>--adapter-path</code>: Path to trained adapter weights (default: adapters)
- <code>--save-path</code>: Output path for fused model (default: fused_model)
- <code>--dequantize</code>: Generate a dequantized model
- <code>--export-gguf</code>: Export model in GGUF format
- <code>--gguf-path</code>: Path for GGUF export (default: ggml-model-f16.gguf)
- <code>--upload</code>: HuggingFace repo to upload fused model to</p>
<p><strong>Supported Model Types for GGUF Export:</strong>
- <code>llama</code> - Llama models
- <code>mixtral</code> - Mixtral models<br />
- <code>mistral</code> - Mistral models</p>
<h3 id="mlx-finetuning">MLX Finetuning</h3>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># LoRA finetuning</span>
super<span class="w"> </span>model<span class="w"> </span>mlx<span class="w"> </span>finetune<span class="w"> </span>microsoft_phi-2<span class="w"> </span>training_data<span class="w"> </span>--type<span class="w"> </span>lora<span class="w"> </span>--iters<span class="w"> </span><span class="m">1000</span>

<span class="c1"># DoRA finetuning</span>
super<span class="w"> </span>model<span class="w"> </span>mlx<span class="w"> </span>finetune<span class="w"> </span>microsoft_phi-2<span class="w"> </span>training_data<span class="w"> </span>--type<span class="w"> </span>dora<span class="w"> </span>--iters<span class="w"> </span><span class="m">1000</span>

<span class="c1"># Full finetuning</span>
super<span class="w"> </span>model<span class="w"> </span>mlx<span class="w"> </span>finetune<span class="w"> </span>microsoft_phi-2<span class="w"> </span>training_data<span class="w"> </span>--type<span class="w"> </span>full<span class="w"> </span>--iters<span class="w"> </span><span class="m">1000</span>
</code></pre></div>
<h3 id="advanced-mlx-configuration">Advanced MLX Configuration</h3>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Custom LoRA parameters</span>
super<span class="w"> </span>model<span class="w"> </span>mlx<span class="w"> </span>finetune<span class="w"> </span>model_name<span class="w"> </span>training_data<span class="w"> </span>--type<span class="w"> </span>lora<span class="w"> </span>--rank<span class="w"> </span><span class="m">8</span><span class="w"> </span>--scale<span class="w"> </span><span class="m">20</span>.0

<span class="c1"># DoRA with dropout</span>
super<span class="w"> </span>model<span class="w"> </span>mlx<span class="w"> </span>finetune<span class="w"> </span>model_name<span class="w"> </span>training_data<span class="w"> </span>--type<span class="w"> </span>dora<span class="w"> </span>--rank<span class="w"> </span><span class="m">8</span><span class="w"> </span>--dropout<span class="w"> </span><span class="m">0</span>.1

<span class="c1"># Full finetuning with gradient checkpointing</span>
super<span class="w"> </span>model<span class="w"> </span>mlx<span class="w"> </span>finetune<span class="w"> </span>model_name<span class="w"> </span>training_data<span class="w"> </span>--type<span class="w"> </span>full<span class="w"> </span>--layers<span class="w"> </span><span class="m">16</span>

<span class="c1"># Advanced training configuration</span>
super<span class="w"> </span>model<span class="w"> </span>mlx<span class="w"> </span>finetune<span class="w"> </span>model_name<span class="w"> </span>training_data<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--type<span class="w"> </span>lora<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--batch-size<span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--lr<span class="w"> </span>1e-5<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--iters<span class="w"> </span><span class="m">1000</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--max-length<span class="w"> </span><span class="m">2048</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--report-steps<span class="w"> </span><span class="m">10</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--eval-steps<span class="w"> </span><span class="m">200</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--save-steps<span class="w"> </span><span class="m">100</span>

<span class="c1"># With WandB logging</span>
super<span class="w"> </span>model<span class="w"> </span>mlx<span class="w"> </span>finetune<span class="w"> </span>model_name<span class="w"> </span>training_data<span class="w"> </span>--wandb<span class="w"> </span>my_project

<span class="c1"># Resume from checkpoint</span>
super<span class="w"> </span>model<span class="w"> </span>mlx<span class="w"> </span>finetune<span class="w"> </span>model_name<span class="w"> </span>training_data<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--resume<span class="w"> </span>checkpoint_path<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--iters<span class="w"> </span><span class="m">500</span>

<span class="c1"># Test after training</span>
super<span class="w"> </span>model<span class="w"> </span>mlx<span class="w"> </span>finetune<span class="w"> </span>model_name<span class="w"> </span>training_data<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--test<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--grad-checkpoint
</code></pre></div>
<h3 id="training-data-format">Training Data Format</h3>
<p>MLX finetuning requires JSONL format:</p>
<div class="language-text highlight"><pre><span></span><code>training_data/
‚îú‚îÄ‚îÄ train.jsonl    # Training examples
‚îú‚îÄ‚îÄ valid.jsonl    # Validation examples
‚îî‚îÄ‚îÄ test.jsonl     # Test examples
</code></pre></div>
<p>Each JSONL file contains one JSON object per line:
<div class="language-json highlight"><pre><span></span><code><span class="p">{</span><span class="nt">&quot;text&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Your training text here&quot;</span><span class="p">}</span>
<span class="p">{</span><span class="nt">&quot;text&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Another training example&quot;</span><span class="p">}</span>
</code></pre></div></p>
<h3 id="vllm-commands">vLLM Commands</h3>
<p>vLLM provides high-performance inference for production environments:</p>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Serve vLLM models</span>
super<span class="w"> </span>model<span class="w"> </span>vllm<span class="w"> </span>serve<span class="w"> </span>llama-2-7b<span class="w"> </span>--host<span class="w"> </span><span class="m">0</span>.0.0.0<span class="w"> </span>--port<span class="w"> </span><span class="m">8000</span>

<span class="c1"># Generate text with vLLM</span>
super<span class="w"> </span>model<span class="w"> </span>vllm<span class="w"> </span>generate<span class="w"> </span>llama-2-7b<span class="w"> </span><span class="s2">&quot;Explain quantum computing&quot;</span><span class="w"> </span>--max-tokens<span class="w"> </span><span class="m">200</span>

<span class="c1"># Benchmark vLLM models</span>
super<span class="w"> </span>model<span class="w"> </span>vllm<span class="w"> </span>benchmark<span class="w"> </span>llama-2-7b<span class="w"> </span>--num-requests<span class="w"> </span><span class="m">100</span><span class="w"> </span>--request-rate<span class="w"> </span><span class="m">10</span>

<span class="c1"># Quantize vLLM models</span>
super<span class="w"> </span>model<span class="w"> </span>vllm<span class="w"> </span>quantize<span class="w"> </span>llama-2-7b<span class="w"> </span>--quantization<span class="w"> </span>awq<span class="w"> </span>--bits<span class="w"> </span><span class="m">4</span>
</code></pre></div>
<h3 id="vllm-setup-requirements">vLLM Setup Requirements</h3>
<p><strong>System Requirements:</strong>
- Linux environment (Ubuntu 20.04+ recommended)
- NVIDIA GPU with CUDA support
- CUDA 11.8+ and cuDNN 8.9+
- Python 3.8+</p>
<p><strong>Dependency Structure:</strong>
- <strong>vLLM is an optional dependency</strong> - not included in base SuperOptiX installation
- Users can install vLLM separately or via SuperOptiX extras
- SuperOptiX provides helpful error messages if vLLM is not available</p>
<p><strong>Installation Options:</strong></p>
<p><strong>Option 1: Install vLLM separately (Recommended)</strong>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Install vLLM directly</span>
pip<span class="w"> </span>install<span class="w"> </span>vllm

<span class="c1"># Verify installation</span>
python<span class="w"> </span>-c<span class="w"> </span><span class="s2">&quot;import vllm; print(&#39;vLLM installed&#39;)&quot;</span>

<span class="c1"># Check GPU support</span>
python<span class="w"> </span>-c<span class="w"> </span><span class="s2">&quot;from vllm import LLM; print(&#39;GPU support available&#39;)&quot;</span>
</code></pre></div></p>
<p><strong>Option 2: Install with SuperOptiX vLLM dependency</strong>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Install SuperOptiX with vLLM support</span>
pip<span class="w"> </span>install<span class="w"> </span>superoptix<span class="o">[</span>vllm<span class="o">]</span>

<span class="c1"># Verify installation</span>
python<span class="w"> </span>-c<span class="w"> </span><span class="s2">&quot;import vllm; print(&#39;vLLM installed via SuperOptiX&#39;)&quot;</span>
</code></pre></div></p>
<p><strong>Note:</strong> 
- vLLM is an <strong>optional dependency</strong> that users need to install separately or via the <code>[vllm]</code> extra
- SuperOptiX will provide helpful error messages if vLLM is not available when trying to use vLLM commands
- vLLM can run on CPU for testing but requires NVIDIA GPU for optimal performance</p>
<h3 id="vllm-serving">vLLM Serving</h3>
<p>Serve models for high-performance inference:</p>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Basic serving</span>
super<span class="w"> </span>model<span class="w"> </span>vllm<span class="w"> </span>serve<span class="w"> </span>llama-2-7b<span class="w"> </span>--host<span class="w"> </span>localhost<span class="w"> </span>--port<span class="w"> </span><span class="m">8000</span>

<span class="c1"># Multi-GPU serving</span>
super<span class="w"> </span>model<span class="w"> </span>vllm<span class="w"> </span>serve<span class="w"> </span>llama-2-7b<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--host<span class="w"> </span><span class="m">0</span>.0.0.0<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--port<span class="w"> </span><span class="m">8000</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tensor-parallel-size<span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--gpu-memory-utilization<span class="w"> </span><span class="m">0</span>.9

<span class="c1"># Quantized model serving</span>
super<span class="w"> </span>model<span class="w"> </span>vllm<span class="w"> </span>serve<span class="w"> </span>llama-2-7b<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--quantization<span class="w"> </span>awq<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--trust-remote-code<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--max-model-len<span class="w"> </span><span class="m">4096</span>
</code></pre></div>
<p><strong>Serving Parameters:</strong>
- <code>--host</code>: Server host (default: localhost)
- <code>--port</code>: Server port (default: 8000)
- <code>--tensor-parallel-size</code>: Number of GPUs for tensor parallelism
- <code>--gpu-memory-utilization</code>: GPU memory utilization (0.0-1.0)
- <code>--max-model-len</code>: Maximum model length
- <code>--quantization</code>: Quantization method (awq, gptq, squeezellm)
- <code>--trust-remote-code</code>: Trust remote code execution
- <code>--download-dir</code>: Directory to download models</p>
<h3 id="vllm-generation">vLLM Generation</h3>
<p>Generate text with high-performance inference:</p>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Basic generation</span>
super<span class="w"> </span>model<span class="w"> </span>vllm<span class="w"> </span>generate<span class="w"> </span>llama-2-7b<span class="w"> </span><span class="s2">&quot;Write a story about&quot;</span><span class="w"> </span>--max-tokens<span class="w"> </span><span class="m">200</span>

<span class="c1"># Streaming generation</span>
super<span class="w"> </span>model<span class="w"> </span>vllm<span class="w"> </span>generate<span class="w"> </span>llama-2-7b<span class="w"> </span><span class="s2">&quot;Explain AI:&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--max-tokens<span class="w"> </span><span class="m">500</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--temperature<span class="w"> </span><span class="m">0</span>.8<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--stream

<span class="c1"># Controlled generation</span>
super<span class="w"> </span>model<span class="w"> </span>vllm<span class="w"> </span>generate<span class="w"> </span>llama-2-7b<span class="w"> </span><span class="s2">&quot;Complete this:&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--max-tokens<span class="w"> </span><span class="m">100</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--temperature<span class="w"> </span><span class="m">0</span>.1<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--top-p<span class="w"> </span><span class="m">0</span>.9<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--stop<span class="w"> </span><span class="s2">&quot;END,###&quot;</span>
</code></pre></div>
<p><strong>Generation Parameters:</strong>
- <code>--max-tokens</code>: Maximum tokens to generate
- <code>--temperature</code>: Sampling temperature (0.0-2.0)
- <code>--top-p</code>: Top-p sampling parameter (0.0-1.0)
- <code>--top-k</code>: Top-k sampling parameter
- <code>--stop</code>: Stop sequences (comma-separated)
- <code>--stream</code>: Enable streaming generation
- <code>--tensor-parallel-size</code>: Number of GPUs
- <code>--quantization</code>: Quantization method</p>
<h3 id="vllm-benchmarking">vLLM Benchmarking</h3>
<p>Benchmark models for performance analysis:</p>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Basic benchmarking</span>
super<span class="w"> </span>model<span class="w"> </span>vllm<span class="w"> </span>benchmark<span class="w"> </span>llama-2-7b<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-requests<span class="w"> </span><span class="m">100</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--request-rate<span class="w"> </span><span class="m">10</span>

<span class="c1"># Performance benchmarking</span>
super<span class="w"> </span>model<span class="w"> </span>vllm<span class="w"> </span>benchmark<span class="w"> </span>llama-2-7b<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-requests<span class="w"> </span><span class="m">1000</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--request-rate<span class="w"> </span><span class="m">50</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--prompt-length<span class="w"> </span><span class="m">512</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--max-tokens<span class="w"> </span><span class="m">128</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tensor-parallel-size<span class="w"> </span><span class="m">2</span>

<span class="c1"># Quantized model benchmarking</span>
super<span class="w"> </span>model<span class="w"> </span>vllm<span class="w"> </span>benchmark<span class="w"> </span>llama-2-7b<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--quantization<span class="w"> </span>awq<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-requests<span class="w"> </span><span class="m">500</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--request-rate<span class="w"> </span><span class="m">25</span>
</code></pre></div>
<p><strong>Benchmarking Parameters:</strong>
- <code>--num-requests</code>: Number of requests to process
- <code>--request-rate</code>: Requests per second
- <code>--prompt-length</code>: Prompt length in tokens
- <code>--max-tokens</code>: Maximum tokens to generate
- <code>--tensor-parallel-size</code>: Number of GPUs
- <code>--quantization</code>: Quantization method</p>
<h3 id="vllm-quantization">vLLM Quantization</h3>
<p>Quantize models for reduced memory usage:</p>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># AWQ quantization</span>
super<span class="w"> </span>model<span class="w"> </span>vllm<span class="w"> </span>quantize<span class="w"> </span>llama-2-7b<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--quantization<span class="w"> </span>awq<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--bits<span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--group-size<span class="w"> </span><span class="m">128</span>

<span class="c1"># GPTQ quantization</span>
super<span class="w"> </span>model<span class="w"> </span>vllm<span class="w"> </span>quantize<span class="w"> </span>llama-2-7b<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--quantization<span class="w"> </span>gptq<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--bits<span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--group-size<span class="w"> </span><span class="m">128</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--trust-remote-code

<span class="c1"># SqueezeLLM quantization</span>
super<span class="w"> </span>model<span class="w"> </span>vllm<span class="w"> </span>quantize<span class="w"> </span>llama-2-7b<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--quantization<span class="w"> </span>squeezellm<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--bits<span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--group-size<span class="w"> </span><span class="m">128</span>
</code></pre></div>
<p><strong>Quantization Parameters:</strong>
- <code>--output-dir</code>: Output directory (default: quantized_model)
- <code>--quantization</code>: Quantization method (awq, gptq, squeezellm)
- <code>--bits</code>: Bits for quantization (2, 3, 4, 8)
- <code>--group-size</code>: Group size for quantization
- <code>--trust-remote-code</code>: Trust remote code execution</p>
<h3 id="vllm-troubleshooting">vLLM Troubleshooting</h3>
<p><strong>Common Issues:</strong>
- <strong>CUDA out of memory</strong>: Reduce <code>--gpu-memory-utilization</code> or use quantization
- <strong>Model not found</strong>: Ensure model is available on HuggingFace Hub
- <strong>Quantization errors</strong>: Check model compatibility with quantization method
- <strong>Performance issues</strong>: Adjust <code>--tensor-parallel-size</code> and <code>--gpu-memory-utilization</code></p>
<p><strong>Performance Optimization:</strong>
- Use appropriate quantization for memory constraints
- Adjust tensor parallelism based on GPU count
- Monitor GPU memory utilization
- Use appropriate model lengths for your use case</p>
<h3 id="sglang-commands">SGLang Commands</h3>
<p>SGLang provides streaming and optimization for production environments:</p>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Serve SGLang models</span>
super<span class="w"> </span>model<span class="w"> </span>sglang<span class="w"> </span>serve<span class="w"> </span>llama-2-7b<span class="w"> </span>--host<span class="w"> </span><span class="m">0</span>.0.0.0<span class="w"> </span>--port<span class="w"> </span><span class="m">8000</span>

<span class="c1"># Generate text with SGLang</span>
super<span class="w"> </span>model<span class="w"> </span>sglang<span class="w"> </span>generate<span class="w"> </span>llama-2-7b<span class="w"> </span><span class="s2">&quot;Explain streaming generation&quot;</span><span class="w"> </span>--max-tokens<span class="w"> </span><span class="m">200</span>

<span class="c1"># Optimize SGLang models</span>
super<span class="w"> </span>model<span class="w"> </span>sglang<span class="w"> </span>optimize<span class="w"> </span>llama-2-7b<span class="w"> </span>--optimization<span class="w"> </span>O2

<span class="c1"># Benchmark SGLang models</span>
super<span class="w"> </span>model<span class="w"> </span>sglang<span class="w"> </span>benchmark<span class="w"> </span>llama-2-7b<span class="w"> </span>--num-requests<span class="w"> </span><span class="m">100</span><span class="w"> </span>--request-rate<span class="w"> </span><span class="m">10</span>
</code></pre></div>
<h3 id="sglang-setup-requirements">SGLang Setup Requirements</h3>
<p><strong>System Requirements:</strong>
- Linux environment (Ubuntu 20.04+ recommended)
- NVIDIA GPU with CUDA support
- CUDA 11.8+ and cuDNN 8.9+
- Python 3.8+</p>
<p><strong>Dependency Structure:</strong>
- <strong>SGLang is an optional dependency</strong> - not included in base SuperOptiX installation
- Users can install SGLang separately or via SuperOptiX extras
- SuperOptiX provides helpful error messages if SGLang is not available</p>
<p><strong>Installation Options:</strong></p>
<p><strong>Option 1: Install SGLang separately (Recommended)</strong>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Install SGLang directly</span>
pip<span class="w"> </span>install<span class="w"> </span>sglang

<span class="c1"># Verify installation</span>
python<span class="w"> </span>-c<span class="w"> </span><span class="s2">&quot;import sglang; print(&#39;SGLang installed&#39;)&quot;</span>

<span class="c1"># Check GPU support</span>
python<span class="w"> </span>-c<span class="w"> </span><span class="s2">&quot;from sglang import SGLang; print(&#39;GPU support available&#39;)&quot;</span>
</code></pre></div></p>
<p><strong>Option 2: Install with SuperOptiX SGLang dependency</strong>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Install SuperOptiX with SGLang support</span>
pip<span class="w"> </span>install<span class="w"> </span>superoptix<span class="o">[</span>sglang<span class="o">]</span>

<span class="c1"># Verify installation</span>
python<span class="w"> </span>-c<span class="w"> </span><span class="s2">&quot;import sglang; print(&#39;SGLang installed via SuperOptiX&#39;)&quot;</span>
</code></pre></div></p>
<p><strong>Note:</strong> 
- SGLang is an <strong>optional dependency</strong> that users need to install separately or via the <code>[sglang]</code> extra
- SuperOptiX will provide helpful error messages if SGLang is not available when trying to use SGLang commands
- SGLang can run on CPU for testing but requires NVIDIA GPU for optimal performance</p>
<h3 id="sglang-serving">SGLang Serving</h3>
<p>Serve models for streaming and optimization:</p>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Basic serving</span>
super<span class="w"> </span>model<span class="w"> </span>sglang<span class="w"> </span>serve<span class="w"> </span>llama-2-7b<span class="w"> </span>--host<span class="w"> </span>localhost<span class="w"> </span>--port<span class="w"> </span><span class="m">8000</span>

<span class="c1"># High-performance serving</span>
super<span class="w"> </span>model<span class="w"> </span>sglang<span class="w"> </span>serve<span class="w"> </span>llama-2-7b<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--host<span class="w"> </span><span class="m">0</span>.0.0.0<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--port<span class="w"> </span><span class="m">8000</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--max-batch-size<span class="w"> </span><span class="m">64</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--max-num-batched-tokens<span class="w"> </span><span class="m">8192</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--max-num-seqs<span class="w"> </span><span class="m">512</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--gpu-memory-utilization<span class="w"> </span><span class="m">0</span>.95

<span class="c1"># Streaming-optimized serving</span>
super<span class="w"> </span>model<span class="w"> </span>sglang<span class="w"> </span>serve<span class="w"> </span>llama-2-7b<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--max-batch-size<span class="w"> </span><span class="m">32</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--max-num-batched-tokens<span class="w"> </span><span class="m">4096</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--trust-remote-code
</code></pre></div>
<p><strong>Serving Parameters:</strong>
- <code>--host</code>: Server host (default: localhost)
- <code>--port</code>: Server port (default: 8000)
- <code>--max-batch-size</code>: Maximum batch size (default: 32)
- <code>--max-num-batched-tokens</code>: Maximum number of batched tokens (default: 4096)
- <code>--max-num-seqs</code>: Maximum number of sequences (default: 256)
- <code>--gpu-memory-utilization</code>: GPU memory utilization (0.0-1.0)
- <code>--trust-remote-code</code>: Trust remote code execution</p>
<h3 id="sglang-generation">SGLang Generation</h3>
<p>Generate text with streaming and optimization:</p>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Basic generation</span>
super<span class="w"> </span>model<span class="w"> </span>sglang<span class="w"> </span>generate<span class="w"> </span>llama-2-7b<span class="w"> </span><span class="s2">&quot;Write a story about&quot;</span><span class="w"> </span>--max-tokens<span class="w"> </span><span class="m">200</span>

<span class="c1"># Streaming generation</span>
super<span class="w"> </span>model<span class="w"> </span>sglang<span class="w"> </span>generate<span class="w"> </span>llama-2-7b<span class="w"> </span><span class="s2">&quot;Explain AI:&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--max-tokens<span class="w"> </span><span class="m">500</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--temperature<span class="w"> </span><span class="m">0</span>.8<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--stream<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--max-batch-size<span class="w"> </span><span class="m">16</span>

<span class="c1"># Optimized generation</span>
super<span class="w"> </span>model<span class="w"> </span>sglang<span class="w"> </span>generate<span class="w"> </span>llama-2-7b<span class="w"> </span><span class="s2">&quot;Complete this:&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--max-tokens<span class="w"> </span><span class="m">100</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--temperature<span class="w"> </span><span class="m">0</span>.1<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--top-p<span class="w"> </span><span class="m">0</span>.9<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--stop<span class="w"> </span><span class="s2">&quot;END,###&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--max-batch-size<span class="w"> </span><span class="m">32</span>
</code></pre></div>
<p><strong>Generation Parameters:</strong>
- <code>--max-tokens</code>: Maximum tokens to generate
- <code>--temperature</code>: Sampling temperature (0.0-2.0)
- <code>--top-p</code>: Top-p sampling parameter (0.0-1.0)
- <code>--top-k</code>: Top-k sampling parameter
- <code>--stop</code>: Stop sequences (comma-separated)
- <code>--stream</code>: Enable streaming generation
- <code>--max-batch-size</code>: Maximum batch size</p>
<h3 id="sglang-optimization">SGLang Optimization</h3>
<p>Optimize models for performance:</p>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Performance optimization</span>
super<span class="w"> </span>model<span class="w"> </span>sglang<span class="w"> </span>optimize<span class="w"> </span>llama-2-7b<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--optimization<span class="w"> </span>O2<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--max-batch-size<span class="w"> </span><span class="m">64</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--max-num-batched-tokens<span class="w"> </span><span class="m">8192</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--gpu-memory-utilization<span class="w"> </span><span class="m">0</span>.95

<span class="c1"># Memory optimization</span>
super<span class="w"> </span>model<span class="w"> </span>sglang<span class="w"> </span>optimize<span class="w"> </span>llama-2-7b<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--optimization<span class="w"> </span>O1<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--max-batch-size<span class="w"> </span><span class="m">32</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--max-num-batched-tokens<span class="w"> </span><span class="m">4096</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--gpu-memory-utilization<span class="w"> </span><span class="m">0</span>.8
</code></pre></div>
<p><strong>Optimization Parameters:</strong>
- <code>--optimization</code>: Optimization level (O0, O1, O2, O3)
- <code>--max-batch-size</code>: Maximum batch size
- <code>--max-num-batched-tokens</code>: Maximum number of batched tokens
- <code>--gpu-memory-utilization</code>: GPU memory utilization
- <code>--trust-remote-code</code>: Trust remote code execution</p>
<h3 id="sglang-benchmarking">SGLang Benchmarking</h3>
<p>Benchmark models for performance analysis:</p>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Basic benchmarking</span>
super<span class="w"> </span>model<span class="w"> </span>sglang<span class="w"> </span>benchmark<span class="w"> </span>llama-2-7b<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-requests<span class="w"> </span><span class="m">100</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--request-rate<span class="w"> </span><span class="m">10</span>

<span class="c1"># Performance benchmarking</span>
super<span class="w"> </span>model<span class="w"> </span>sglang<span class="w"> </span>benchmark<span class="w"> </span>llama-2-7b<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-requests<span class="w"> </span><span class="m">1000</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--request-rate<span class="w"> </span><span class="m">50</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--prompt-length<span class="w"> </span><span class="m">512</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--max-tokens<span class="w"> </span><span class="m">128</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--max-batch-size<span class="w"> </span><span class="m">64</span>

<span class="c1"># Streaming benchmarking</span>
super<span class="w"> </span>model<span class="w"> </span>sglang<span class="w"> </span>benchmark<span class="w"> </span>llama-2-7b<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-requests<span class="w"> </span><span class="m">500</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--request-rate<span class="w"> </span><span class="m">25</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--prompt-length<span class="w"> </span><span class="m">256</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--max-tokens<span class="w"> </span><span class="m">64</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--max-batch-size<span class="w"> </span><span class="m">32</span>
</code></pre></div>
<p><strong>Benchmarking Parameters:</strong>
- <code>--num-requests</code>: Number of requests to process
- <code>--request-rate</code>: Requests per second
- <code>--prompt-length</code>: Prompt length in tokens
- <code>--max-tokens</code>: Maximum tokens to generate
- <code>--max-batch-size</code>: Maximum batch size</p>
<h3 id="sglang-troubleshooting">SGLang Troubleshooting</h3>
<p><strong>Common Issues:</strong>
- <strong>CUDA out of memory</strong>: Reduce <code>--gpu-memory-utilization</code> or batch size
- <strong>Model not found</strong>: Ensure model is available on HuggingFace Hub
- <strong>Streaming errors</strong>: Check <code>--max-batch-size</code> and <code>--max-num-batched-tokens</code>
- <strong>Performance issues</strong>: Adjust optimization level and batch parameters</p>
<p><strong>Performance Optimization:</strong>
- Use appropriate optimization levels (O0-O3) for your use case
- Adjust batch sizes based on GPU memory
- Monitor GPU memory utilization
- Use streaming for real-time applications</p>
<h2 id="server-management">Server Management</h2>
<h3 id="starting-local-servers">Starting Local Servers</h3>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Start MLX server</span>
super<span class="w"> </span>model<span class="w"> </span>server<span class="w"> </span>mlx<span class="w"> </span>mlx-community/phi-2<span class="w"> </span>--port<span class="w"> </span><span class="m">8000</span>

<span class="c1"># Start HuggingFace server</span>
super<span class="w"> </span>model<span class="w"> </span>server<span class="w"> </span>huggingface<span class="w"> </span>microsoft/phi-1_5<span class="w"> </span>--port<span class="w"> </span><span class="m">8001</span>
</code></pre></div>
<h3 id="using-servers-in-playbooks">Using Servers in Playbooks</h3>
<div class="language-yaml highlight"><pre><span></span><code><span class="nt">language_model</span><span class="p">:</span>
<span class="w">  </span><span class="nt">provider</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">mlx</span>
<span class="w">  </span><span class="nt">model</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">mlx-community/phi-2</span>
<span class="w">  </span><span class="nt">api_base</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">http://localhost:8000</span>
</code></pre></div>
<h3 id="model-conversion-and-quantization">Model Conversion and Quantization</h3>
<p>Convert and quantize models for MLX backend:</p>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Convert HuggingFace model to MLX format</span>
super<span class="w"> </span>model<span class="w"> </span>convert<span class="w"> </span>microsoft/phi-2<span class="w"> </span>--quantize<span class="w"> </span>--bits<span class="w"> </span><span class="m">4</span>

<span class="c1"># Quantize existing MLX model</span>
super<span class="w"> </span>model<span class="w"> </span>quantize<span class="w"> </span>my-model<span class="w"> </span>--bits<span class="w"> </span><span class="m">4</span><span class="w"> </span>--output<span class="w"> </span>my-model-q4

<span class="c1"># Dequantize a quantized model</span>
super<span class="w"> </span>model<span class="w"> </span>quantize<span class="w"> </span>my-model-q4<span class="w"> </span>--dequantize<span class="w"> </span>--output<span class="w"> </span>my-model-dequantized
</code></pre></div>
<p><strong>Note:</strong> These commands are experimental and require MLX backend to be available.</p>
<h2 id="troubleshooting">Troubleshooting</h2>
<h3 id="common-issues">Common Issues</h3>
<p><strong>Model not found:</strong>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Check available models</span>
super<span class="w"> </span>model<span class="w"> </span>list<span class="w"> </span>--backend<span class="w"> </span>&lt;backend&gt;

<span class="c1"># Install missing model</span>
super<span class="w"> </span>model<span class="w"> </span>install<span class="w"> </span>&lt;model_name&gt;<span class="w"> </span>--backend<span class="w"> </span>&lt;backend&gt;

<span class="c1"># Refresh cache</span>
super<span class="w"> </span>model<span class="w"> </span>refresh
</code></pre></div></p>
<p><strong>Backend not working:</strong>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Check backend status</span>
super<span class="w"> </span>model<span class="w"> </span>backends

<span class="c1"># Verify installation</span>
super<span class="w"> </span>model<span class="w"> </span>info<span class="w"> </span>&lt;model_name&gt;
</code></pre></div></p>
<p><strong>LM Studio models:</strong>
- LM Studio models must be installed via the desktop app
- Use <code>super model server lmstudio &lt;model&gt;</code> to start server
- Models cannot be removed via CLI (use desktop app)</p>
<p><strong>MLX Evaluation Issues:</strong>
- <strong>Missing lm_eval</strong>: Install with <code>pip install lm_eval</code>
- <strong>Model not found</strong>: Ensure model is properly installed with <code>super model list --backend mlx</code>
- <strong>Memory issues</strong>: Use <code>--limit</code> to reduce evaluation examples
- <strong>Slow evaluation</strong>: Use <code>--batch-size</code> to optimize performance</p>
<p><strong>MLX Fusion Issues:</strong>
- <strong>Adapter not found</strong>: Check adapter path with <code>ls adapters/</code>
- <strong>Model type unsupported</strong>: GGUF export supports llama, mixtral, mistral only
- <strong>Upload failed</strong>: Ensure HuggingFace token is configured
- <strong>Local model not found</strong>: Use full path to local model directory
- <strong>404 HuggingFace error</strong>: Ensure model exists on HuggingFace Hub or use local path</p>
<h3 id="auto-installation-workflow">Auto-Installation Workflow</h3>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Try to run model (auto-installs if needed)</span>
super<span class="w"> </span>model<span class="w"> </span>run<span class="w"> </span>&lt;model_name&gt;<span class="w"> </span><span class="s2">&quot;test&quot;</span>

<span class="c1"># Install explicitly if needed</span>
super<span class="w"> </span>model<span class="w"> </span>install<span class="w"> </span>&lt;model_name&gt;<span class="w"> </span>--backend<span class="w"> </span>&lt;backend&gt;

<span class="c1"># Run again</span>
super<span class="w"> </span>model<span class="w"> </span>run<span class="w"> </span>&lt;model_name&gt;<span class="w"> </span><span class="s2">&quot;test&quot;</span><span class="w"> </span>--backend<span class="w"> </span>&lt;backend&gt;
</code></pre></div>
<h2 id="best-practices">Best Practices</h2>
<h3 id="model-selection">Model Selection</h3>
<ul>
<li><strong>Small models</strong>: Good for testing and development</li>
<li><strong>Medium models</strong>: Balance of performance and resource usage</li>
<li><strong>Large models</strong>: Best performance, requires more resources</li>
</ul>
<h2 id="resources">Resources</h2>
<ul>
<li><a href="https://superoptix.ai">SuperOptiX Documentation</a> - Complete framework documentation</li>
<li><a href="https://dspy.ai">DSPy Framework</a> - Foundation framework</li>
<li><a href="https://huggingface.co/openai/gpt-oss-120b">GPT-OSS-120B Model</a> - HuggingFace repository</li>
<li><a href="https://huggingface.co/openai/gpt-oss-20b">GPT-OSS-20B Model</a> - HuggingFace repository</li>
<li><a href="https://ollama.com/library/gpt-oss">Ollama Library</a> - Ollama model library</li>
</ul>
<h2 id="next-steps">Next Steps</h2>
<h3 id="backend-selection">Backend Selection</h3>
<ul>
<li><strong>Ollama</strong>: Easiest for local development</li>
<li><strong>MLX</strong>: Best for Apple Silicon performance</li>
<li><strong>HuggingFace</strong>: Widest model support</li>
<li><strong>LM Studio</strong>: Good for desktop workflows</li>
</ul>
<h3 id="performance-optimization">Performance Optimization</h3>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Use appropriate model sizes</span>
super<span class="w"> </span>model<span class="w"> </span>list<span class="w"> </span>--size<span class="w"> </span>small<span class="w">    </span><span class="c1"># For testing</span>
super<span class="w"> </span>model<span class="w"> </span>list<span class="w"> </span>--size<span class="w"> </span>medium<span class="w">   </span><span class="c1"># For development</span>
super<span class="w"> </span>model<span class="w"> </span>list<span class="w"> </span>--size<span class="w"> </span>large<span class="w">    </span><span class="c1"># For production</span>

<span class="c1"># Optimize generation parameters</span>
super<span class="w"> </span>model<span class="w"> </span>run<span class="w"> </span>model<span class="w"> </span><span class="s2">&quot;prompt&quot;</span><span class="w"> </span>--max-tokens<span class="w"> </span><span class="m">100</span><span class="w"> </span>--temperature<span class="w"> </span><span class="m">0</span>.7
</code></pre></div>
<h2 id="examples">Examples</h2>
<h3 id="complete-workflow">Complete Workflow</h3>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Discover models</span>
super<span class="w"> </span>model<span class="w"> </span>discover

<span class="c1"># Install model</span>
super<span class="w"> </span>model<span class="w"> </span>install<span class="w"> </span>llama3.2:3b<span class="w"> </span>--backend<span class="w"> </span>ollama

<span class="c1"># Run model</span>
super<span class="w"> </span>model<span class="w"> </span>run<span class="w"> </span>llama3.2:3b<span class="w"> </span><span class="s2">&quot;Write a Python function to sort a list&quot;</span>

<span class="c1"># Try different model</span>
super<span class="w"> </span>model<span class="w"> </span>run<span class="w"> </span>microsoft/phi-1_5<span class="w"> </span><span class="s2">&quot;Write a JavaScript function to validate email&quot;</span>

<span class="c1"># Interactive session</span>
super<span class="w"> </span>model<span class="w"> </span>run<span class="w"> </span>llama3.2:3b<span class="w"> </span><span class="s2">&quot;Write a blog post about AI trends&quot;</span>

<span class="c1"># Try MLX model</span>
super<span class="w"> </span>model<span class="w"> </span>run<span class="w"> </span>mlx-community/phi-2<span class="w"> </span><span class="s2">&quot;Write a short story about a robot&quot;</span>

<span class="c1"># Advanced usage</span>
super<span class="w"> </span>model<span class="w"> </span>run<span class="w"> </span>microsoft/phi-1_5<span class="w"> </span><span class="s2">&quot;Analyze this text: [your text here]&quot;</span>

<span class="c1"># Educational</span>
super<span class="w"> </span>model<span class="w"> </span>run<span class="w"> </span>llama3.2:3b<span class="w"> </span><span class="s2">&quot;Explain machine learning in simple terms&quot;</span>
</code></pre></div>
<h3 id="testing-mlx-features">Testing MLX Features</h3>
<p><strong>1. Verify Dependencies:</strong>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Check MLX-LM installation</span>
python<span class="w"> </span>-c<span class="w"> </span><span class="s2">&quot;import mlx_lm; print(&#39;MLX-LM installed&#39;)&quot;</span>

<span class="c1"># Check LM-Eval installation (for evaluation)</span>
python<span class="w"> </span>-c<span class="w"> </span><span class="s2">&quot;import lm_eval; print(&#39;LM-Eval installed&#39;)&quot;</span>
</code></pre></div></p>
<p><strong>2. Test Command Structure:</strong>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Verify all MLX commands are available</span>
super<span class="w"> </span>model<span class="w"> </span>mlx<span class="w"> </span>--help
super<span class="w"> </span>model<span class="w"> </span>mlx<span class="w"> </span>evaluate<span class="w"> </span>--help
super<span class="w"> </span>model<span class="w"> </span>mlx<span class="w"> </span>fuse<span class="w"> </span>--help
super<span class="w"> </span>model<span class="w"> </span>mlx<span class="w"> </span>finetune<span class="w"> </span>--help
super<span class="w"> </span>model<span class="w"> </span>mlx<span class="w"> </span>convert<span class="w"> </span>--help
super<span class="w"> </span>model<span class="w"> </span>mlx<span class="w"> </span>quantize<span class="w"> </span>--help
</code></pre></div></p>
<p><strong>3. Test with Real Models:</strong>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># List available MLX models</span>
super<span class="w"> </span>model<span class="w"> </span>list<span class="w"> </span>--backend<span class="w"> </span>mlx

<span class="c1"># Test evaluation (requires lm_eval)</span>
super<span class="w"> </span>model<span class="w"> </span>mlx<span class="w"> </span>evaluate<span class="w"> </span>microsoft_phi-2<span class="w"> </span>--tasks<span class="w"> </span>mmlu<span class="w"> </span>--limit<span class="w"> </span><span class="m">10</span>

<span class="c1"># Test fusion (requires adapter files)</span>
super<span class="w"> </span>model<span class="w"> </span>mlx<span class="w"> </span>fuse<span class="w"> </span>microsoft_phi-2<span class="w"> </span>--adapter-path<span class="w"> </span>./adapters
</code></pre></div></p>
<p><strong>4. Common Test Scenarios:</strong>
- <strong>Evaluation</strong>: Test with small models and limited examples
- <strong>Fusion</strong>: Test with existing adapter files from finetuning
- <strong>Error Handling</strong>: Test with non-existent models/paths
- <strong>Performance</strong>: Test with different batch sizes and limits </p>
<h2 id="dependency-overview">Dependency Overview</h2>
<p>SuperOptiX uses a modular dependency structure to keep the base installation lightweight:</p>
<h3 id="core-dependencies-always-included"><strong>Core Dependencies</strong> (Always Included)</h3>
<ul>
<li>Basic CLI functionality</li>
<li>Model management</li>
<li>DSPy integration</li>
<li>Core utilities</li>
</ul>
<h3 id="optional-dependencies-install-as-needed"><strong>Optional Dependencies</strong> (Install as needed)</h3>
<p><strong>Backend-Specific:</strong>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># MLX (Apple Silicon only)</span>
pip<span class="w"> </span>install<span class="w"> </span>superoptix<span class="o">[</span>mlx<span class="o">]</span>

<span class="c1"># vLLM (Linux with NVIDIA GPU)</span>
pip<span class="w"> </span>install<span class="w"> </span>superoptix<span class="o">[</span>vllm<span class="o">]</span>

<span class="c1"># SGLang (Linux with NVIDIA GPU)</span>
pip<span class="w"> </span>install<span class="w"> </span>superoptix<span class="o">[</span>sglang<span class="o">]</span>

<span class="c1"># HuggingFace (Cross-platform)</span>
pip<span class="w"> </span>install<span class="w"> </span>superoptix<span class="o">[</span>huggingface<span class="o">]</span>
</code></pre></div></p>
<p><strong>Vector Databases:</strong>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># Individual databases</span>
pip<span class="w"> </span>install<span class="w"> </span>superoptix<span class="o">[</span>chromadb<span class="o">]</span>
pip<span class="w"> </span>install<span class="w"> </span>superoptix<span class="o">[</span>lancedb<span class="o">]</span>
pip<span class="w"> </span>install<span class="w"> </span>superoptix<span class="o">[</span>weaviate<span class="o">]</span>
pip<span class="w"> </span>install<span class="w"> </span>superoptix<span class="o">[</span>qdrant<span class="o">]</span>
pip<span class="w"> </span>install<span class="w"> </span>superoptix<span class="o">[</span>milvus<span class="o">]</span>

<span class="c1"># All vector databases</span>
pip<span class="w"> </span>install<span class="w"> </span>superoptix<span class="o">[</span>vectordb<span class="o">]</span>
</code></pre></div></p>
<p><strong>Observability:</strong>
<div class="language-bash highlight"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>superoptix<span class="o">[</span>observability<span class="o">]</span>
</code></pre></div></p>
<p><strong>UI Components:</strong>
<div class="language-bash highlight"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>superoptix<span class="o">[</span>ui<span class="o">]</span>
</code></pre></div></p>
<p><strong>Complete Installation:</strong>
<div class="language-bash highlight"><pre><span></span><code><span class="c1"># All features (excluding MLX on non-Apple platforms)</span>
pip<span class="w"> </span>install<span class="w"> </span>superoptix<span class="o">[</span>all<span class="o">]</span>

<span class="c1"># All features including MLX (use with caution on non-Apple platforms)</span>
pip<span class="w"> </span>install<span class="w"> </span>superoptix<span class="o">[</span>all-with-mlx<span class="o">]</span>
</code></pre></div></p>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright ¬© 2025 Superagentic AI. Made with ‚ù§Ô∏è for the Agentic AI community.
    </div>
  
  
</div>
      
        
<div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/SuperagenticAI" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://x.com/SuperagenticAI" target="_blank" rel="noopener" title="x.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M459.4 151.7c.3 4.5.3 9.1.3 13.6 0 138.7-105.6 298.6-298.6 298.6-59.5 0-114.7-17.2-161.1-47.1 8.4 1 16.6 1.3 25.3 1.3 49.1 0 94.2-16.6 130.3-44.8-46.1-1-84.8-31.2-98.1-72.8 6.5 1 13 1.6 19.8 1.6 9.4 0 18.8-1.3 27.6-3.6-48.1-9.7-84.1-52-84.1-103v-1.3c14 7.8 30.2 12.7 47.4 13.3-28.3-18.8-46.8-51-46.8-87.4 0-19.5 5.2-37.4 14.3-53C87.4 130.8 165 172.4 252.1 176.9c-1.6-7.8-2.6-15.9-2.6-24C249.5 95.1 296.3 48 354.4 48c30.2 0 57.5 12.7 76.7 33.1 23.7-4.5 46.5-13.3 66.6-25.3-7.8 24.4-24.4 44.8-46.1 57.8 21.1-2.3 41.6-8.1 60.4-16.2-14.3 20.8-32.2 39.3-52.6 54.3"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://www.linkedin.com/company/superagenticai" target="_blank" rel="noopener" title="www.linkedin.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zM102.2 96a38.5 38.5 0 1 1 0 77 38.5 38.5 0 1 1 0-77m282.1 320h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../..", "features": ["navigation.instant.prefetch", "navigation.tracking", "navigation.path", "navigation.top", "search.suggest", "search.highlight", "search.share", "content.code.copy", "content.code.annotate", "content.tabs.link"], "search": "../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.79ae519e.min.js"></script>
      
        <script src="https://unpkg.com/mermaid@10/dist/mermaid.min.js"></script>
      
        <script src="../../javascripts/extra.js"></script>
      
    
  </body>
</html>